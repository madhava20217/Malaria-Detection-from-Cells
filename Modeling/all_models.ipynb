{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import skimage\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage.transform import rescale, resize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import bz2, pickle, _pickle as cPickle\n",
    "\n",
    "import random\n",
    "\n",
    "# random.seed(1234)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\Modules\\\\Testing\")\n",
    "import testing_module\n",
    "\n",
    "SAVE_DIR = \"../Pickled Datasets/\"\n",
    "\n",
    "HEIGHT = 25\n",
    "WIDTH  = 25\n",
    "\n",
    "\n",
    "def compressed_pickle(name: str, data):\n",
    "    with bz2.BZ2File(os.path.join(SAVE_DIR, \"{}.pbz2\".format(name)), 'w') as f:\n",
    "        cPickle.dump(data, f)\n",
    "\n",
    "def decompress_pickle(file):\n",
    "    data = bz2.BZ2File(file, 'rb')\n",
    "    data = cPickle.load(data)\n",
    "    return data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKImage rescales the image for us! Which means that we don't need to rescale by 255.0 anymore, saving us needlessly spent time and effort. There is another Augmentor library which can be used for data augmentation. We can simply sample the augmented images henceforth!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.dirname(os.path.join((os.path.pardir), \"Modules\")))\n",
    "\n",
    "origin_dir = os.path.join(os.path.pardir, 'Data')\n",
    "new_dir_path = os.path.join(os.path.pardir, 'Data', 'cell_images')\n",
    "\n",
    "#for local systems\n",
    "train_csv = os.path.join(origin_dir, 'train.csv')\n",
    "test_csv = os.path.join(origin_dir, 'test.csv')\n",
    "val_csv = os.path.join(origin_dir, 'val.csv')\n",
    "\n",
    "from Modules.labelling import Labelling\n",
    "\n",
    "# download = Data_Download(origin_dir)\n",
    "# data_dir = download.resize_image(new_dir_path, 44, 44)\n",
    "\n",
    "lab = Labelling()\n",
    "lab.label('../Data/cell_images/', exclude_mislabeled= True)      # function to label the dataset\n",
    "train_csv, val_csv, test_csv = lab.train_test_val_split('../Data/', '../Data/cell_images/labels.csv', random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_csv)\n",
    "val_data   = pd.read_csv(val_csv)\n",
    "test_data  = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    '''Function to read images given a path and return an array'''\n",
    "    return skimage.io.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/cell_images/Parasitized\\C39P4thinF_original_IMG_20150622_105102_cell_95.png\n",
      "0.9966666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20a47255bd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 14\n",
    "\n",
    "print(train_data['Image_Path'][i])\n",
    "image = rgb2hsv(skimage.io.imread(train_data['Image_Path'][i]))\n",
    "print(np.max(image))\n",
    "result = ((image > 0.5)*image)[..., 1]\n",
    "plt.imshow(result, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20601/20601 [00:29<00:00, 701.03it/s]\n",
      "100%|██████████| 2943/2943 [00:04<00:00, 695.30it/s]\n",
      "100%|██████████| 2617/2617 [00:03<00:00, 673.35it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "train_data['image_arr'] = train_data['Image_Path'].progress_apply(lambda x: read_image(x))\n",
    "val_data['image_arr']   = val_data['Image_Path'].progress_apply(lambda x: read_image(x))\n",
    "test_data['image_arr']  = test_data['Image_Path'].progress_apply(lambda x: read_image(x))\n",
    "\n",
    "\n",
    "x_train, y_train = train_data['image_arr'].to_numpy(), train_data['Parasitized'].to_numpy()\n",
    "x_val  , y_val   = val_data['image_arr'].to_numpy()  , val_data['Parasitized'].to_numpy()\n",
    "x_test , y_test  = test_data['image_arr'].to_numpy() , test_data['Parasitized'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20601it [00:05, 3576.25it/s]\n"
     ]
    }
   ],
   "source": [
    "augment = A.augmentations.geometric.transforms.Affine(\n",
    "    translate_percent = 0.1,\n",
    "    rotate = 60,\n",
    "    shear = 30\n",
    "    )\n",
    "\n",
    "augment = A.ShiftScaleRotate(rotate_limit= 180, border_mode=cv2.BORDER_CONSTANT, always_apply= True)\n",
    "\n",
    "transform = A.Compose(\n",
    "    [augment,\n",
    "    A.VerticalFlip(p = 0.5),\n",
    "    A.HorizontalFlip(p = 0.5),\n",
    "    A.augmentations.geometric.Affine(shear = 15),\n",
    "    A.Resize(HEIGHT, WIDTH, always_apply= True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "aug_dataset = []\n",
    "aug_labels = []\n",
    "COPIES = 2\n",
    "\n",
    "for i, lab in tqdm(zip(x_train, y_train)):\n",
    "    for _ in range(COPIES):\n",
    "        aug_dataset.append(transform(image = i)['image'])\n",
    "        aug_labels.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_aug = np.array(aug_dataset)\n",
    "y_train_aug = np.array(aug_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([20520, 20682], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_aug, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20601/20601 [00:20<00:00, 998.63it/s] \n",
      "100%|██████████| 2943/2943 [00:02<00:00, 1087.52it/s]\n",
      "100%|██████████| 2617/2617 [00:02<00:00, 1094.98it/s]\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "for img in tqdm(x_train):\n",
    "    temp.append(resize(img, (HEIGHT, WIDTH)))\n",
    "x_train = np.array(temp)\n",
    "\n",
    "\n",
    "temp = []\n",
    "for img in tqdm(x_val):\n",
    "    temp.append(resize(img, (HEIGHT, WIDTH)))\n",
    "x_val = np.array(temp)\n",
    "\n",
    "\n",
    "temp = []\n",
    "for img in tqdm(x_test):\n",
    "    temp.append(resize(img, (HEIGHT, WIDTH)))\n",
    "x_test = np.array(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_pickle(\"x_train_aug\", x_train_aug)\n",
    "compressed_pickle(\"y_train_aug\", y_train_aug)\n",
    "compressed_pickle(\"x_train\", x_train)\n",
    "compressed_pickle(\"y_train\", y_train)\n",
    "compressed_pickle(\"x_val\", x_val)\n",
    "compressed_pickle(\"y_val\", y_val)\n",
    "compressed_pickle(\"x_test\", x_test)\n",
    "compressed_pickle(\"y_test\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented:  (41202, 25, 25, 3) (41202,)\n",
      "train:  (20601, 25, 25, 3) (20601,)\n",
      "val:  (2943, 25, 25, 3) (2943,)\n",
      "test:  (2617, 25, 25, 3) (2617,)\n"
     ]
    }
   ],
   "source": [
    "x_train_aug = decompress_pickle(SAVE_DIR + 'x_train_aug.pbz2')\n",
    "y_train_aug = decompress_pickle(SAVE_DIR + 'y_train_aug.pbz2')\n",
    "x_train = decompress_pickle(SAVE_DIR + 'x_train.pbz2')\n",
    "y_train = decompress_pickle(SAVE_DIR + 'y_train.pbz2')\n",
    "x_val = decompress_pickle(SAVE_DIR + 'x_val.pbz2')\n",
    "y_val = decompress_pickle(SAVE_DIR + 'y_val.pbz2')\n",
    "x_test = decompress_pickle(SAVE_DIR + 'x_test.pbz2')\n",
    "y_test = decompress_pickle(SAVE_DIR + 'y_test.pbz2')\n",
    "\n",
    "print(\"augmented: \", x_train_aug.shape, y_train_aug.shape)\n",
    "print(\"train: \", x_train.shape, y_train.shape)\n",
    "print(\"val: \", x_val.shape, y_val.shape)\n",
    "print(\"test: \", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_aug_train = x_train_aug.shape[0]\n",
    "n_train     = x_train.shape[0]\n",
    "n_val       = x_val.shape[0]\n",
    "n_test      = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20ae93600a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DIGITS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unaugmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.611     0.746     0.672     10260\n",
      "         1.0      0.677     0.530     0.594     10341\n",
      "\n",
      "    accuracy                          0.637     20601\n",
      "   macro avg      0.644     0.638     0.633     20601\n",
      "weighted avg      0.644     0.637     0.633     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.620     0.761     0.683      1466\n",
      "         1.0      0.693     0.538     0.606      1477\n",
      "\n",
      "    accuracy                          0.649      2943\n",
      "   macro avg      0.657     0.649     0.644      2943\n",
      "weighted avg      0.657     0.649     0.644      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.613     0.766     0.681      1303\n",
      "         1.0      0.692     0.521     0.595      1314\n",
      "\n",
      "    accuracy                          0.643      2617\n",
      "   macro avg      0.653     0.644     0.638      2617\n",
      "weighted avg      0.653     0.643     0.638      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "nb_cls = naive_bayes.GaussianNB()\n",
    "nb_cls.fit(x_train.reshape(n_train, -1), y_train)\n",
    "preds_train = nb_cls.predict(x_train.reshape(n_train, -1))\n",
    "preds_val   = nb_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = nb_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n",
    "# eval = testing_module.ModelEvaluation(y_val, \n",
    "#     nb_cls.predict(x_val.reshape(n_val, -1)),\n",
    "#     model_reference_name = 'Naive Bayes',\n",
    "#     model_type = 'classification',\n",
    "#     plot_classification_metric = ['roc_auc']) # if classification\n",
    "# eval.evaluate(evaluate_save= True, plots_show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 43 seconds\n",
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.729     0.754     0.741     10260\n",
      "         1.0      0.747     0.722     0.734     10341\n",
      "\n",
      "    accuracy                          0.738     20601\n",
      "   macro avg      0.738     0.738     0.738     20601\n",
      "weighted avg      0.738     0.738     0.738     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.693     0.714     0.703      1466\n",
      "         1.0      0.707     0.686     0.696      1477\n",
      "\n",
      "    accuracy                          0.700      2943\n",
      "   macro avg      0.700     0.700     0.700      2943\n",
      "weighted avg      0.700     0.700     0.700      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.689     0.738     0.712      1303\n",
      "         1.0      0.720     0.670     0.694      1314\n",
      "\n",
      "    accuracy                          0.703      2617\n",
      "   macro avg      0.705     0.704     0.703      2617\n",
      "weighted avg      0.705     0.703     0.703      2617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   43.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_cls =  LogisticRegression(max_iter = 200, verbose = 10, n_jobs = -1, solver = 'saga')\n",
    "logreg_cls.fit(x_train.reshape(n_train, -1), y_train)\n",
    "preds_train = logreg_cls.predict(x_train.reshape(n_train, -1))\n",
    "preds_val   = logreg_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = logreg_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n",
    "# eval = testing_module.ModelEvaluation(y_val, \n",
    "#     nb_cls.predict(x_val.reshape(n_val, -1)),\n",
    "#     model_reference_name = 'Naive Bayes',\n",
    "#     model_type = 'classification',\n",
    "#     plot_classification_metric = ['roc_auc']) # if classification\n",
    "# eval.evaluate(evaluate_save= True, plots_show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.685     0.774     0.727     10260\n",
      "         1.0      0.743     0.646     0.691     10341\n",
      "\n",
      "    accuracy                          0.710     20601\n",
      "   macro avg      0.714     0.710     0.709     20601\n",
      "weighted avg      0.714     0.710     0.709     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.677     0.774     0.722      1466\n",
      "         1.0      0.738     0.634     0.682      1477\n",
      "\n",
      "    accuracy                          0.703      2943\n",
      "   macro avg      0.708     0.704     0.702      2943\n",
      "weighted avg      0.708     0.703     0.702      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.662     0.748     0.703      1303\n",
      "         1.0      0.714     0.622     0.664      1314\n",
      "\n",
      "    accuracy                          0.685      2617\n",
      "   macro avg      0.688     0.685     0.684      2617\n",
      "weighted avg      0.688     0.685     0.684      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_cls =  DecisionTreeClassifier(criterion = 'gini', splitter = 'best', max_depth = 5, min_samples_split = 2, )\n",
    "dt_cls.fit(x_train.reshape(n_train, -1), y_train)\n",
    "preds_train = dt_cls.predict(x_train.reshape(n_train, -1))\n",
    "preds_val   = dt_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = dt_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n",
    "# eval = testing_module.ModelEvaluation(y_val, \n",
    "#     nb_cls.predict(x_val.reshape(n_val, -1)),\n",
    "#     model_reference_name = 'Naive Bayes',\n",
    "#     model_type = 'classification',\n",
    "#     plot_classification_metric = ['roc_auc']) # if classification\n",
    "# eval.evaluate(evaluate_save= True, plots_show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.966     0.983     0.974     10260\n",
      "         1.0      0.983     0.966     0.974     10341\n",
      "\n",
      "    accuracy                          0.974     20601\n",
      "   macro avg      0.974     0.974     0.974     20601\n",
      "weighted avg      0.975     0.974     0.974     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.842     0.873     0.857      1466\n",
      "         1.0      0.869     0.837     0.853      1477\n",
      "\n",
      "    accuracy                          0.855      2943\n",
      "   macro avg      0.855     0.855     0.855      2943\n",
      "weighted avg      0.855     0.855     0.855      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.842     0.861     0.851      1303\n",
      "         1.0      0.859     0.839     0.849      1314\n",
      "\n",
      "    accuracy                          0.850      2617\n",
      "   macro avg      0.850     0.850     0.850      2617\n",
      "weighted avg      0.850     0.850     0.850      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_cls = XGBClassifier(max_depth = 5, objective = 'reg:logistic',\n",
    "                            num_parallel_tree = 20, booster = 'gbtree',\n",
    "                            gamma = 0.5, tree_method = 'gpu_hist', subsample = 0.4, reg_lambda = 1)\n",
    "xgb_cls.fit(x_train.reshape(n_train, -1), y_train)\n",
    "preds_train = xgb_cls.predict(x_train.reshape(n_train, -1))\n",
    "preds_val   = xgb_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = xgb_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=250).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.456     0.498     0.476     10260\n",
      "         1.0      0.452     0.411     0.430     10341\n",
      "\n",
      "    accuracy                          0.454     20601\n",
      "   macro avg      0.454     0.454     0.453     20601\n",
      "weighted avg      0.454     0.454     0.453     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.446     0.477     0.461      1466\n",
      "         1.0      0.442     0.412     0.426      1477\n",
      "\n",
      "    accuracy                          0.444      2943\n",
      "   macro avg      0.444     0.444     0.444      2943\n",
      "weighted avg      0.444     0.444     0.444      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.457     0.486     0.471      1303\n",
      "         1.0      0.456     0.428     0.441      1314\n",
      "\n",
      "    accuracy                          0.457      2617\n",
      "   macro avg      0.457     0.457     0.456      2617\n",
      "weighted avg      0.457     0.457     0.456      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_cls = SVC(kernel = 'rbf', max_iter = 250, verbose= True)\n",
    "svm_cls.fit(x_train.reshape(n_train, -1), y_train)\n",
    "preds_train = svm_cls.predict(x_train.reshape(n_train, -1))\n",
    "preds_val   = svm_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = svm_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "322/322 [==============================] - 9s 17ms/step - loss: 0.2140 - accuracy: 0.9201 - val_loss: 0.1365 - val_accuracy: 0.9514\n",
      "Epoch 2/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.1240 - accuracy: 0.9504 - val_loss: 0.1341 - val_accuracy: 0.9470\n",
      "Epoch 3/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.1077 - accuracy: 0.9583 - val_loss: 0.1331 - val_accuracy: 0.9531\n",
      "Epoch 4/50\n",
      "322/322 [==============================] - 5s 16ms/step - loss: 0.0971 - accuracy: 0.9615 - val_loss: 0.1074 - val_accuracy: 0.9630\n",
      "Epoch 5/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.0927 - accuracy: 0.9634 - val_loss: 0.1137 - val_accuracy: 0.9623\n",
      "Epoch 6/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.0866 - accuracy: 0.9669 - val_loss: 0.2217 - val_accuracy: 0.9320\n",
      "Epoch 7/50\n",
      "322/322 [==============================] - 5s 16ms/step - loss: 0.0826 - accuracy: 0.9692 - val_loss: 0.1359 - val_accuracy: 0.9521\n",
      "644/644 [==============================] - 5s 7ms/step\n",
      "92/92 [==============================] - 1s 6ms/step\n",
      "82/82 [==============================] - 1s 7ms/step\n",
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.979     0.956     0.967     10260\n",
      "         1.0      0.957     0.980     0.968     10341\n",
      "\n",
      "    accuracy                          0.968     20601\n",
      "   macro avg      0.968     0.968     0.968     20601\n",
      "weighted avg      0.968     0.968     0.968     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.970     0.933     0.951      1466\n",
      "         1.0      0.936     0.971     0.953      1477\n",
      "\n",
      "    accuracy                          0.952      2943\n",
      "   macro avg      0.953     0.952     0.952      2943\n",
      "weighted avg      0.953     0.952     0.952      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.958     0.924     0.941      1303\n",
      "         1.0      0.927     0.960     0.943      1314\n",
      "\n",
      "    accuracy                          0.942      2617\n",
      "   macro avg      0.943     0.942     0.942      2617\n",
      "weighted avg      0.942     0.942     0.942      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagenet = tf.keras.applications.Xception(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = (72, 72, 3)\n",
    ")\n",
    "imagenet.trainable = False\n",
    "\n",
    "trans_learn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(72, 72),\n",
    "    imagenet,\n",
    "\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "trans_learn.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = trans_learn.fit(\n",
    "            x_train, y_train, batch_size = 64,\n",
    "            shuffle = True,\n",
    "            epochs = 50,\n",
    "            validation_data = [x_val, y_val],\n",
    "            validation_batch_size = 32,\n",
    "            callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "        )\n",
    "preds_train = np.argmax(trans_learn.predict(x_train), axis = 1)\n",
    "preds_val   = np.argmax(trans_learn.predict(x_val), axis = 1)\n",
    "preds_test  = np.argmax(trans_learn.predict(x_test), axis = 1)\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 16ms/step - loss: 0.6991 - accuracy: 0.5436 - val_loss: 0.6575 - val_accuracy: 0.5906\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.6421 - accuracy: 0.6313 - val_loss: 0.5956 - val_accuracy: 0.6854\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.5946 - accuracy: 0.6853 - val_loss: 0.6197 - val_accuracy: 0.6232\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.7279 - val_loss: 0.5453 - val_accuracy: 0.7159\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.5019 - accuracy: 0.7666 - val_loss: 0.9244 - val_accuracy: 0.5070\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.6034 - accuracy: 0.6656 - val_loss: 0.5038 - val_accuracy: 0.7530\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.4677 - accuracy: 0.7900 - val_loss: 0.4338 - val_accuracy: 0.8073\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8208 - val_loss: 0.3803 - val_accuracy: 0.8440\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.8469 - val_loss: 0.3600 - val_accuracy: 0.8529\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3450 - accuracy: 0.8558 - val_loss: 0.2894 - val_accuracy: 0.8807\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2568 - accuracy: 0.8992 - val_loss: 0.2091 - val_accuracy: 0.9140\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2013 - accuracy: 0.9231 - val_loss: 0.2499 - val_accuracy: 0.8936\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1793 - accuracy: 0.9326 - val_loss: 0.1308 - val_accuracy: 0.9545\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.9498 - val_loss: 0.1061 - val_accuracy: 0.9592\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.1105 - accuracy: 0.9611 - val_loss: 0.0926 - val_accuracy: 0.9687\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0938 - accuracy: 0.9667 - val_loss: 0.0766 - val_accuracy: 0.9718\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0783 - accuracy: 0.9721 - val_loss: 0.0836 - val_accuracy: 0.9728\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0720 - accuracy: 0.9756 - val_loss: 0.0752 - val_accuracy: 0.9759\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 0.9761 - val_loss: 0.0660 - val_accuracy: 0.9789\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9805 - val_loss: 0.0657 - val_accuracy: 0.9762\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0652 - accuracy: 0.9780 - val_loss: 0.0570 - val_accuracy: 0.9803\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0570 - accuracy: 0.9810 - val_loss: 0.0533 - val_accuracy: 0.9830\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.9838 - val_loss: 0.0559 - val_accuracy: 0.9850\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.9835 - val_loss: 0.0484 - val_accuracy: 0.9850\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.0576 - val_accuracy: 0.9823\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0456 - accuracy: 0.9850 - val_loss: 0.0476 - val_accuracy: 0.9864\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9860 - val_loss: 0.0521 - val_accuracy: 0.9857\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.0562 - val_accuracy: 0.9820\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0357 - accuracy: 0.9888 - val_loss: 0.0475 - val_accuracy: 0.9878\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9901 - val_loss: 0.0478 - val_accuracy: 0.9878\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0381 - accuracy: 0.9868 - val_loss: 0.0456 - val_accuracy: 0.9854\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9880 - val_loss: 0.0424 - val_accuracy: 0.9864\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.0513 - val_accuracy: 0.9847\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 0.0484 - val_accuracy: 0.9867\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 0.0448 - val_accuracy: 0.9881\n",
      "644/644 [==============================] - 1s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "82/82 [==============================] - 0s 1ms/step\n",
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.995     0.997     0.996     10260\n",
      "         1.0      0.997     0.995     0.996     10341\n",
      "\n",
      "    accuracy                          0.996     20601\n",
      "   macro avg      0.996     0.996     0.996     20601\n",
      "weighted avg      0.996     0.996     0.996     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.987     0.989     0.988      1466\n",
      "         1.0      0.989     0.987     0.988      1477\n",
      "\n",
      "    accuracy                          0.988      2943\n",
      "   macro avg      0.988     0.988     0.988      2943\n",
      "weighted avg      0.988     0.988     0.988      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.980     0.989     0.985      1303\n",
      "         1.0      0.989     0.980     0.985      1314\n",
      "\n",
      "    accuracy                          0.985      2617\n",
      "   macro avg      0.985     0.985     0.985      2617\n",
      "weighted avg      0.985     0.985     0.985      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), padding = 'same', activation = 'relu', input_shape = x_train[0].shape),\n",
    "    tf.keras.layers.MaxPool2D((3,3), padding = 'same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (2,2), padding = 'same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2), padding = 'same'),\n",
    "\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cnn.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = cnn.fit(\n",
    "            x_train, y_train, batch_size = 1024,\n",
    "            epochs = 50,\n",
    "            validation_data = [x_val, y_val],\n",
    "            validation_batch_size = 256,\n",
    "            callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "        )\n",
    "preds_train = np.argmax(cnn.predict(x_train), axis = 1)\n",
    "preds_val   = np.argmax(cnn.predict(x_val), axis = 1)\n",
    "preds_test  = np.argmax(cnn.predict(x_test), axis = 1)\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.615     0.733     0.669     20520\n",
      "         1.0      0.673     0.544     0.601     20682\n",
      "\n",
      "    accuracy                          0.638     41202\n",
      "   macro avg      0.644     0.638     0.635     41202\n",
      "weighted avg      0.644     0.638     0.635     41202\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.605     0.815     0.694      1466\n",
      "         1.0      0.720     0.471     0.570      1477\n",
      "\n",
      "    accuracy                          0.643      2943\n",
      "   macro avg      0.662     0.643     0.632      2943\n",
      "weighted avg      0.662     0.643     0.632      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.604     0.813     0.693      1303\n",
      "         1.0      0.717     0.471     0.569      1314\n",
      "\n",
      "    accuracy                          0.641      2617\n",
      "   macro avg      0.661     0.642     0.631      2617\n",
      "weighted avg      0.661     0.641     0.630      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "nb_cls = naive_bayes.GaussianNB()\n",
    "nb_cls.fit(x_train_aug.reshape(n_aug_train, -1), y_train_aug)\n",
    "preds_train = nb_cls.predict(x_train_aug.reshape(n_aug_train, -1))\n",
    "preds_val   = nb_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = nb_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 88 seconds\n",
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.681     0.724     0.702     20520\n",
      "         1.0      0.708     0.663     0.685     20682\n",
      "\n",
      "    accuracy                          0.694     41202\n",
      "   macro avg      0.694     0.694     0.693     41202\n",
      "weighted avg      0.694     0.694     0.693     41202\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.657     0.731     0.692      1466\n",
      "         1.0      0.699     0.622     0.659      1477\n",
      "\n",
      "    accuracy                          0.676      2943\n",
      "   macro avg      0.678     0.676     0.675      2943\n",
      "weighted avg      0.679     0.676     0.675      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.659     0.732     0.694      1303\n",
      "         1.0      0.701     0.624     0.660      1314\n",
      "\n",
      "    accuracy                          0.678      2617\n",
      "   macro avg      0.680     0.678     0.677      2617\n",
      "weighted avg      0.680     0.678     0.677      2617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_cls =  LogisticRegression(max_iter = 200, verbose = 10, n_jobs = -1, solver = 'saga')\n",
    "logreg_cls.fit(x_train_aug.reshape(n_aug_train, -1), y_train_aug)\n",
    "preds_train = logreg_cls.predict(x_train_aug.reshape(n_aug_train, -1))\n",
    "preds_val   = logreg_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = logreg_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.859     0.962     0.908     20520\n",
      "         1.0      0.957     0.844     0.897     20682\n",
      "\n",
      "    accuracy                          0.903     41202\n",
      "   macro avg      0.908     0.903     0.902     41202\n",
      "weighted avg      0.908     0.903     0.902     41202\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.690     0.802     0.741      1466\n",
      "         1.0      0.765     0.642     0.698      1477\n",
      "\n",
      "    accuracy                          0.721      2943\n",
      "   macro avg      0.727     0.722     0.720      2943\n",
      "weighted avg      0.727     0.721     0.720      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.679     0.815     0.741      1303\n",
      "         1.0      0.771     0.617     0.686      1314\n",
      "\n",
      "    accuracy                          0.716      2617\n",
      "   macro avg      0.725     0.716     0.713      2617\n",
      "weighted avg      0.725     0.716     0.713      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_cls =  DecisionTreeClassifier(criterion = 'gini', splitter = 'best', max_depth = 20, min_samples_split = 2, )\n",
    "dt_cls.fit(x_train_aug.reshape(n_aug_train, -1), y_train_aug)\n",
    "preds_train = dt_cls.predict(x_train_aug.reshape(n_aug_train, -1))\n",
    "preds_val   = dt_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = dt_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n",
    "# eval = testing_module.ModelEvaluation(y_val, \n",
    "#     nb_cls.predict(x_val.reshape(n_val, -1)),\n",
    "#     model_reference_name = 'Naive Bayes',\n",
    "#     model_type = 'classification',\n",
    "#     plot_classification_metric = ['roc_auc']) # if classification\n",
    "# eval.evaluate(evaluate_save= True, plots_show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.910     0.947     0.928     20520\n",
      "         1.0      0.945     0.907     0.926     20682\n",
      "\n",
      "    accuracy                          0.927     41202\n",
      "   macro avg      0.928     0.927     0.927     41202\n",
      "weighted avg      0.928     0.927     0.927     41202\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.840     0.884     0.861      1466\n",
      "         1.0      0.879     0.833     0.855      1477\n",
      "\n",
      "    accuracy                          0.858      2943\n",
      "   macro avg      0.859     0.858     0.858      2943\n",
      "weighted avg      0.859     0.858     0.858      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.833     0.883     0.857      1303\n",
      "         1.0      0.876     0.824     0.849      1314\n",
      "\n",
      "    accuracy                          0.853      2617\n",
      "   macro avg      0.854     0.853     0.853      2617\n",
      "weighted avg      0.855     0.853     0.853      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_cls = XGBClassifier(max_depth = 5, objective = 'reg:logistic',\n",
    "                            num_parallel_tree = 20, booster = 'gbtree',\n",
    "                            gamma = 0.5, tree_method = 'gpu_hist', subsample = 0.4, reg_lambda = 1)\n",
    "xgb_cls.fit(x_train_aug.reshape(n_aug_train, -1), y_train_aug)\n",
    "preds_train = xgb_cls.predict(x_train_aug.reshape(n_aug_train, -1))\n",
    "preds_val   = xgb_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = xgb_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=250).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.428     0.210     0.282     20520\n",
      "         1.0      0.479     0.721     0.576     20682\n",
      "\n",
      "    accuracy                          0.467     41202\n",
      "   macro avg      0.453     0.466     0.429     41202\n",
      "weighted avg      0.453     0.467     0.429     41202\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.430     0.204     0.277      1466\n",
      "         1.0      0.481     0.731     0.580      1477\n",
      "\n",
      "    accuracy                          0.469      2943\n",
      "   macro avg      0.455     0.468     0.428      2943\n",
      "weighted avg      0.455     0.469     0.429      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.427     0.194     0.267      1303\n",
      "         1.0      0.481     0.741     0.584      1314\n",
      "\n",
      "    accuracy                          0.469      2617\n",
      "   macro avg      0.454     0.468     0.425      2617\n",
      "weighted avg      0.454     0.469     0.426      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_cls = SVC(kernel = 'rbf', max_iter = 250, verbose= True)\n",
    "svm_cls.fit(x_train_aug.reshape(n_aug_train, -1), y_train_aug)\n",
    "preds_train = svm_cls.predict(x_train_aug.reshape(n_aug_train, -1))\n",
    "preds_val   = svm_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = svm_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "322/322 [==============================] - 10s 26ms/step - loss: 0.2370 - accuracy: 0.8979 - val_loss: 0.2188 - val_accuracy: 0.9181\n",
      "Epoch 2/50\n",
      "322/322 [==============================] - 8s 24ms/step - loss: 0.1750 - accuracy: 0.9283 - val_loss: 0.1545 - val_accuracy: 0.9433\n",
      "Epoch 3/50\n",
      "322/322 [==============================] - 8s 24ms/step - loss: 0.1510 - accuracy: 0.9379 - val_loss: 0.1316 - val_accuracy: 0.9551\n",
      "Epoch 4/50\n",
      "322/322 [==============================] - 8s 24ms/step - loss: 0.1471 - accuracy: 0.9417 - val_loss: 0.1297 - val_accuracy: 0.9589\n",
      "Epoch 5/50\n",
      "322/322 [==============================] - 8s 24ms/step - loss: 0.1335 - accuracy: 0.9469 - val_loss: 0.1356 - val_accuracy: 0.9555\n",
      "Epoch 6/50\n",
      "322/322 [==============================] - 8s 24ms/step - loss: 0.1292 - accuracy: 0.9487 - val_loss: 0.1310 - val_accuracy: 0.9541\n",
      "Epoch 7/50\n",
      "322/322 [==============================] - 8s 24ms/step - loss: 0.1205 - accuracy: 0.9524 - val_loss: 0.1347 - val_accuracy: 0.9606\n",
      "1288/1288 [==============================] - 9s 7ms/step\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "82/82 [==============================] - 1s 7ms/step\n",
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.940     0.982     0.961     20520\n",
      "         1.0      0.982     0.938     0.959     20682\n",
      "\n",
      "    accuracy                          0.960     41202\n",
      "   macro avg      0.961     0.960     0.960     41202\n",
      "weighted avg      0.961     0.960     0.960     41202\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.966     0.954     0.960      1466\n",
      "         1.0      0.955     0.967     0.961      1477\n",
      "\n",
      "    accuracy                          0.961      2943\n",
      "   macro avg      0.961     0.961     0.961      2943\n",
      "weighted avg      0.961     0.961     0.961      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.956     0.959     0.957      1303\n",
      "         1.0      0.959     0.956     0.957      1314\n",
      "\n",
      "    accuracy                          0.957      2617\n",
      "   macro avg      0.957     0.957     0.957      2617\n",
      "weighted avg      0.957     0.957     0.957      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagenet = tf.keras.applications.Xception(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = (72, 72, 3)\n",
    ")\n",
    "imagenet.trainable = False\n",
    "\n",
    "trans_learn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(72, 72),\n",
    "    imagenet,\n",
    "\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "trans_learn.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = trans_learn.fit(\n",
    "            x_train_aug, y_train_aug, batch_size = 128,\n",
    "            shuffle = True,\n",
    "            epochs = 50,\n",
    "            validation_data = [x_val, y_val],\n",
    "            validation_batch_size = 64,\n",
    "            callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "        )\n",
    "preds_train = np.argmax(trans_learn.predict(x_train_aug), axis = 1)\n",
    "preds_val   = np.argmax(trans_learn.predict(x_val), axis = 1)\n",
    "preds_test  = np.argmax(trans_learn.predict(x_test), axis = 1)\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6625 - accuracy: 0.5915 - val_loss: 0.5915 - val_accuracy: 0.6871\n",
      "Epoch 2/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.5588 - accuracy: 0.7250 - val_loss: 0.4455 - val_accuracy: 0.8026\n",
      "Epoch 3/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7844 - val_loss: 0.3913 - val_accuracy: 0.8172\n",
      "Epoch 4/50\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8225 - val_loss: 0.2972 - val_accuracy: 0.8658\n",
      "Epoch 5/50\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.8581 - val_loss: 0.2298 - val_accuracy: 0.9032\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.8869 - val_loss: 0.1571 - val_accuracy: 0.9368\n",
      "Epoch 7/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2197 - accuracy: 0.9145 - val_loss: 0.1262 - val_accuracy: 0.9484\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9312 - val_loss: 0.0899 - val_accuracy: 0.9670\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.1465 - accuracy: 0.9454 - val_loss: 0.0922 - val_accuracy: 0.9670\n",
      "Epoch 10/50\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 0.1324 - accuracy: 0.9501 - val_loss: 0.0593 - val_accuracy: 0.9779\n",
      "Epoch 11/50\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.9569 - val_loss: 0.0626 - val_accuracy: 0.9766\n",
      "Epoch 12/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9632 - val_loss: 0.0545 - val_accuracy: 0.9810\n",
      "Epoch 13/50\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9647 - val_loss: 0.0575 - val_accuracy: 0.9803\n",
      "Epoch 14/50\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.9696 - val_loss: 0.0417 - val_accuracy: 0.9864\n",
      "Epoch 15/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9729 - val_loss: 0.0634 - val_accuracy: 0.9776\n",
      "Epoch 16/50\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9728 - val_loss: 0.0484 - val_accuracy: 0.9850\n",
      "Epoch 17/50\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9766 - val_loss: 0.0423 - val_accuracy: 0.9874\n",
      "1288/1288 [==============================] - 1s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "82/82 [==============================] - 0s 1ms/step\n",
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.971     0.991     0.981     20520\n",
      "         1.0      0.991     0.971     0.981     20682\n",
      "\n",
      "    accuracy                          0.981     41202\n",
      "   macro avg      0.981     0.981     0.981     41202\n",
      "weighted avg      0.981     0.981     0.981     41202\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.991     0.984     0.987      1466\n",
      "         1.0      0.984     0.991     0.988      1477\n",
      "\n",
      "    accuracy                          0.987      2943\n",
      "   macro avg      0.987     0.987     0.987      2943\n",
      "weighted avg      0.987     0.987     0.987      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.983     0.979     0.981      1303\n",
      "         1.0      0.980     0.983     0.981      1314\n",
      "\n",
      "    accuracy                          0.981      2617\n",
      "   macro avg      0.981     0.981     0.981      2617\n",
      "weighted avg      0.981     0.981     0.981      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), padding = 'same', activation = 'relu', input_shape = x_train_aug[0].shape),\n",
    "    tf.keras.layers.MaxPool2D((3,3), padding = 'same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (2,2), padding = 'same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2), padding = 'same'),\n",
    "\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cnn.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = cnn.fit(\n",
    "            x_train_aug, y_train_aug, batch_size = 512,\n",
    "            epochs = 50,\n",
    "            validation_data = [x_val, y_val],\n",
    "            validation_batch_size = 128,\n",
    "            callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "        )\n",
    "preds_train = np.argmax(cnn.predict(x_train_aug), axis = 1)\n",
    "preds_val   = np.argmax(cnn.predict(x_val), axis = 1)\n",
    "preds_test  = np.argmax(cnn.predict(x_test), axis = 1)\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c58e9361bde7ca617934da376e83056db506761bdc9593ca2087fabac973f609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
