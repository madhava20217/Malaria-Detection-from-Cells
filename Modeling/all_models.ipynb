{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import skimage\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage.transform import rescale, resize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import bz2, pickle, _pickle as cPickle\n",
    "\n",
    "import random\n",
    "\n",
    "# random.seed(1234)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\Modules\\\\Testing\")\n",
    "import testing_module\n",
    "\n",
    "SAVE_DIR = \"../Pickled Datasets/\"\n",
    "\n",
    "HEIGHT = 25\n",
    "WIDTH  = 25\n",
    "\n",
    "\n",
    "def compressed_pickle(name: str, data):\n",
    "    with bz2.BZ2File(os.path.join(SAVE_DIR, \"{}.pbz2\".format(name)), 'w') as f:\n",
    "        cPickle.dump(data, f)\n",
    "\n",
    "def decompress_pickle(file):\n",
    "    data = bz2.BZ2File(file, 'rb')\n",
    "    data = cPickle.load(data)\n",
    "    return data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKImage rescales the image for us! Which means that we don't need to rescale by 255.0 anymore, saving us needlessly spent time and effort. There is another Augmentor library which can be used for data augmentation. We can simply sample the augmented images henceforth!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.dirname(os.path.join((os.path.pardir), \"Modules\")))\n",
    "\n",
    "origin_dir = os.path.join(os.path.pardir, 'Data')\n",
    "new_dir_path = os.path.join(os.path.pardir, 'Data', 'cell_images')\n",
    "\n",
    "#for local systems\n",
    "train_csv = os.path.join(origin_dir, 'train.csv')\n",
    "test_csv = os.path.join(origin_dir, 'test.csv')\n",
    "val_csv = os.path.join(origin_dir, 'val.csv')\n",
    "\n",
    "from Modules.labelling import Labelling\n",
    "\n",
    "# download = Data_Download(origin_dir)\n",
    "# data_dir = download.resize_image(new_dir_path, 44, 44)\n",
    "\n",
    "lab = Labelling()\n",
    "lab.label('../Data/cell_images/', exclude_mislabeled= True)      # function to label the dataset\n",
    "train_csv, val_csv, test_csv = lab.train_test_val_split('../Data/', '../Data/cell_images/labels.csv', random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_csv)\n",
    "val_data   = pd.read_csv(val_csv)\n",
    "test_data  = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    '''Function to read images given a path and return an array'''\n",
    "    return skimage.io.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/cell_images/Parasitized\\C39P4thinF_original_IMG_20150622_105102_cell_95.png\n",
      "0.9966666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f086ad5c00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAGlCAYAAAAh9itiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAw6ElEQVR4nO3de3RV5Z3G8efkXHISSChQkmARQVzxCAYIcl0VxNSyXIrtIG1nCViLYPFKWy9gB1pEqvXCIIo3HFCqkgEtFmHU8TJeplNBCSKuRYiICRQsScQAMZCc654/WHs3B1BCOLxnJ3w/a2Ulefebvd9fTzmP797v3sdjWZYlAAAMyEj3AAAApw9CBwBgDKEDADCG0AEAGEPoAACMIXQAAMYQOgAAYwgdAIAxhA4AwJi0hE4ikdAjjzyikSNHauDAgbruuuu0a9eudAwFAGBQWkLn8ccfV2lpqebNm6cVK1YokUho6tSpikQi6RgOAMAQ46ETiUT09NNPa/r06Ro9erRCoZAeeughVVdX64033jA9HACAQcZDp6KiQgcPHtSIESOcttzcXPXt21cbNmwwPRwAgEE+0wesrq6WJHXv3j2pPS8vz9l2omKxmLxer2pqahSLxU56jOnk8/mUn59PLS5DLe5ELe5QUFCgaDSqrKys4/Y1HjqNjY2SpEAgkNSemZmpAwcOtGqfXq9XHo9HBQUFJz0+t6AWd6IWd6KW9Pv73/+us88++7j9jIdOMBiUdPjajv2zJIXD4Ral5LHU1NSooKBAEyZMUEVFRUrGmS6hUEilpaXU4jLU4k7U4g5r1qxpcV/joWOfVqutrVXPnj2d9traWp177rmt2qc9Fa2oqNCmTZtOfpAuQC3uRC3uRC3pdSIrj40vJAiFQurYsaM++OADp62+vl7l5eUaMmSI6eEAAAwyPtMJBAKaNGmS5s+fry5duuh73/ueHnzwQRUUFGjMmDGmhwMAMMh46EjS9OnTFYvFNHv2bDU1NWnIkCFaunSp/H5/OoYDADAkLaHj9Xp1xx136I477kjH4QEAacIDPwEAxhA6AABjCB0AgDGEDgDAGEIHAGAMoQMAMIbQAQAYQ+gAAIwhdAAAxhA6AABjCB0AgDGEDgDAGEIHAGAMoQMAMIbQAQAYQ+gAAIwhdAAAxhA6AABjCB0AgDGEDgDAGEIHAGAMoQMAMIbQAQAYQ+gAAIwhdAAAxhA6AABjCB0AgDGEDgDAGEIHAGAMoQMAMIbQAQAYQ+gAAIwhdAAAxhA6AABjCB0AgDGEDgDAGEIHAGAMoQMAMIbQAQAYk/LQ2b9/v37/+99r1KhRGjRokK666iqVlZU529etW6crr7xSAwYM0KWXXqpXXnkl1UMAALhUykPn1ltv1aZNm7RgwQKtWrVK5513nqZMmaLKykp9/vnnmjZtmkaOHKmXXnpJP/3pTzVjxgytW7cu1cMAALiQL5U727lzp/72t7+ptLRUF1xwgSTpd7/7nf76179q7dq1+uqrr3TuuefqN7/5jSSpT58+Ki8v15IlSzRixIhUDgUA4EIpnel07txZTz31lIqKipw2j8cjj8ej+vp6lZWVHRUuw4cP18aNG2VZViqHAgBwoZTOdHJzc3XRRRcltb3++uvauXOn/u3f/k1/+ctfVFBQkLQ9Ly9PjY2N2rdvn7p06dKq4/p8h8sIhUKtG7iL2DVQi7tQiztRizsEAgFFIpEW9fVYp3CK8dFHH2nq1Kn6/ve/r0WLFqlv3766++679ZOf/MTps27dOv3iF7/Qe++9d1QgtZRlWfJ4PKkaNgDgBFVWVurss88+br+UznSae+utt3T77bdr0KBBmj9/viQpMzPzqDS0f8/Kymr1sWpqalRQUKAJEyaooqKi9YN2gVAopNLSUmpxGWpxJ2pxhzVr1rS47ykJneeff1733HOPLr30Ut1///0KBAKSpO7du6u2tjapb21trbKzs5WTk9Pq48ViMUlSRUWFNm3a1PqBuwi1uBO1uBO1pFdLT61Jp2DJdGlpqebNm6eJEydqwYIFTuBI0uDBg/Xhhx8m9V+/fr0GDRqkjAzuUwWA9i6lM52qqirde++9+uEPf6hp06Zp7969zrZgMKirr75a48aN0/z58zVu3Di99957+u///m8tWbIklcMAALhUSkPn9ddfVzQa1Ztvvqk333wzadu4ceN033336fHHH9eDDz6oP/3pT+rRo4cefPBB7tEBgNNESkPn+uuv1/XXX/+tfUaNGqVRo0al8rAAgDaCCykAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhzSj6uGnCDjIwMde7cWR07dpTH43HamkskErIsS/X19dq/f78sy0rHUIHTBqGDdsvv92vQoEEaMGCAvF6v/H6/PB6PE0CJRELhcFixWEwbN27UunXrFI1G0zxqoH0jdNAuZWRkyO/367vf/a7OOuss+Xw++f1+ZWRkOMETj8fV1NSkSCSiqqoq+Xw+xeNxJRKJdA8faLcIHbQ7eXl5KiwsVKdOndSzZ08FAgH5/X5lZ2fL6/UqIyNDGRkZisfj8vv9ikajOvfccxWLxbR//35VVFRo79696S4DaJcIHbQ7eXl5uuiii9S1a1dlZ2crMzNTgUBAHTp0kN/vl8/nk9frVTwel8/nUywWU9++fdWjRw/V1NRo7969hA5wihA6aHe8Xq+CwaCCwaACgYBzPSczM9MJHPs0m9/vlyRlZmaqQ4cOysnJUX5+vr7++mtZlqVEIqF4PK7MzMw0VwW0D4QO2h07dLKystShQwdlZWUpMzNTnTt3lt/vTwoTj8ejWCymQCCgQCCgzMxMXXbZZaqvr1ckElE4HNbXX3+tr776Kt1lAe0CoYN2JyMjQz6fTz6fLylMgsGg/H6/4vG44vG4c13HXkZtWZZ8Pp969+6taDSqSCSiQ4cOqa6uTo2NjWmuCmgfCB20C4FAQL1791a3bt109tlnKysry1mxFggE5PP5nBmO/RWPxxWLxZwve+WavXqNe3aA1CN00C4Eg0ENGjRIxcXFysrKUk5OjrxerwKBgILBoBM69izHDp1IJKJYLOZ8bx5KdkgBSB0eg4N2wePxKDMzU1lZWQoGg86yaI/Hk3T6rPnXsfbR/OZRGzMeIHWY6aDd8Hg88nq9zrUce3m0HT7NZy/2lx1K9kzI3ock5+kEhA6QOoQO2hV7puL1epOWRns8HmeG0/y6TfPZjR1AGRkZTgB906wIQOsQOmg37MCw78uxn7Vms39ufsqt+X079mo2e1HBN51uA9B6hA7aDTs4fD6fMjMzjwqe5gFiz2SCwaCzwMBexWYvKmg+8wGQGoQO2pUjT5cd2W7/bH9vvrCg+am4I/dB8ACpQeigXWg+K2m+cs0OlmMFUfPrNXaf5ivemt/nwyk2IDUIHbQrRy4KONY26fDMpflNoM37Ng8u+8kGAFKDf01oV+zVac0/jO3I2c6RgWP38Xq9zqNw7JtH7ZkPgNQgdNAuNF8KHYlE1NjYqGg0qmAwqEQi4QSNHS7Nw8QOI/tD3oLBoBNAjY2NLCYAUojQQbsRjUbV2NjoPDna/nTQ5jOX4y0uOPKaEDMdILUIHbQLjY2NKisr0+7du9WrVy8NGzZMubm5SafJfD6fM9M58gZS++fmp9ssy1I0GlU0GuUZbECKEDpoFyKRiLZs2aItW7boggsuUCgUcj6gzV4oYJ8+O9ZCAfv0WvNFBc0fEAogNQgdtBv2LOXIjyuIx+NJz1Wzr/HYX7FYzPluL0KIRqPat2+fKisrVVdXp0OHDqW5OqB9IHTQ7iQSCTU1NTmLACQlLSSwr9HYp9Ps7/bptIMHD6qpqUlbtmzR2rVrdeDAAfXq1SuNFQHtxyldklNVVaXi4mK99NJLTtvWrVs1adIkDRw4UCUlJXr22WdP5RBwGkokEgqHw87HTYfDYUWjUedzdI71wW3xeNzpEw6HdejQIe3bt0+7d+/Wnj171NTUlO6ygHbhlM10otGobr/99qTTEvv27dPkyZNVUlKiuXPn6uOPP9bcuXPVoUMHjR8//lQNBaeZL7/8Uu+//76ys7Od56/l5eVp4MCBys3NdU7D2YHT/GkG9fX1Kisr0z/+8Q9VVVUpEomkuRqgfTllobNo0SJ17Ngxqe2FF16Q3+/X3XffLZ/Ppz59+mjnzp166qmnCB2kTG1trfbu3Zu01DkUCqlnz57KyspK+qgCewZjf9ZOdXW13nnnHZWXlzsLCQCkzikJnQ0bNmjlypVavXq1Ro8e7bSXlZVp6NChSY8VGT58uBYvXqy9e/fqu9/97qkYDk4zxwqLQ4cO6R//+IdisdhRfaV/hs7evXt18ODBo/oBSI2Uh059fb1mzJih2bNnq3v37knbqqurVVhYmNSWl5cnSdqzZ0+rQ8cOsVAo1Kq/dxO7BmpJraysLFVWVmr37t1J7c1nPfb1nvz8fOXm5ib1c1MtJ4ta3Kkt1xIIBFp8KjrloXPXXXepuLhYV1xxxVHbmpqaFAgEktoyMzMlSeFwuNXHzM/PlySVlpa2eh9uQy3uRC3uRC3pV1lZ2aJ+KQ2d1atXq6ysTGvXrj3m9mAweFQa2mGTnZ3d6uPW1NSooKBAEyZMUEVFRav34wahUEilpaXU4jLU4k7U4g5r1qxpcd+Uhs6qVav01VdfJV3HkaQ5c+bo1VdfVUFBgWpra5O22b/bs5XWsM+/V1RUaNOmTa3ej5tQiztRiztRS3qdyCrPlIbO/Pnzj7qfYcyYMZo+fbp+9KMf6eWXX9aKFSsUj8fl9XolSevXr1fv3r3VtWvXVA4FAOBCKb05ND8/X2eddVbSlyR17dpV+fn5Gj9+vBoaGjRr1ixt375dL730kpYtW6Zp06alchgAAJcy+iEhXbt21ZIlS1RVVaVx48bp0Ucf1YwZMzRu3DiTwwAApMkpf/bap59+mvR7//79tXLlylN9WACAC/FxiAAAYwgdAIAxhA4AwBhCBwBgDKEDADCG0AEAGEPoAACMIXQAAMYQOgAAYwgdAIAxhA4AwBhCBwBgDKEDADCG0AEAGEPoAACMIXQAAMYQOgAAYwgdAIAxhA4AwBhCBwBgDKEDADCG0AEAGEPoAACMIXQAAMYQOgAAYwgdAIAxhA4AwBhCBwBgDKEDADCG0AEAGEPoAACMIXQAAMYQOgAAYwgdAIAxhA4AwBhCBwBgDKEDADCG0AEAGEPoAACMOSWhs3r1al122WUqKirS5Zdfrtdee83Ztnv3bk2bNk2DBg3ShRdeqIULFyoej5+KYQAAXCblofPyyy9r1qxZmjhxol555RWNHTtWt956qzZt2qRoNKopU6ZIklasWKG77rpL//mf/6nHHnss1cMAALiQL5U7syxLDz/8sH7+859r4sSJkqQbbrhBZWVl+vDDD/XFF1/oH//4h1544QV16tRJhYWF+uqrr/TAAw/o+uuvVyAQSOVwAAAuk9KZTlVVlb744gtdccUVSe1Lly7VtGnTVFZWpn79+qlTp07OtuHDh6uhoUFbt25N5VAAAC6U0plOVVWVJOnQoUOaMmWKysvL1aNHD91www0qKSlRdXW1CgoKkv4mLy9PkrRnzx4NGDCgVcf1+Q6XEQqFTmL07mDXQC3uQi3uRC3uEAgEFIlEWtTXY1mWlaoDv/zyy5oxY4Z69Oihm2++WaFQSK+//rqefPJJPfPMM1q8eLHy8vL0wAMPOH+TSCR03nnn6YEHHtCPf/zjVh3Xsix5PJ5UlQEAOEGVlZU6++yzj9svpTMdv98vSZoyZYrGjRsnSTrvvPNUXl6uZ555RsFg8Kg0DIfDkqTs7OxWH7empkYFBQWaMGGCKioqWr0fNwiFQiotLaUWl6EWd6IWd1izZk2L+6Y0dPLz8yVJhYWFSe3nnHOO3n33XQ0dOlTbtm1L2lZbW5v0t60Ri8UkSRUVFdq0aVOr9+Mm1OJO1OJO1JJeLT21JqV4IUG/fv3UoUMHbd68Oal927Zt6tmzp4YMGaLy8nI1NDQ429avX68OHTq0yfOYAIATk9LQCQaDmjp1qh577DH913/9l/7+97/riSee0N/+9jdNnjxZl1xyibp166Zf//rXqqio0FtvvaUFCxbo2muvZbk0AJwGUnp6TZJuvPFGZWVl6aGHHlJNTY369OmjRYsWadiwYZKkJUuWaO7cufrZz36mTp06acKECbrxxhtTPQwAgAulPHQkafLkyZo8efIxt5111ll6+umnT8VhAQAuxwM/AQDGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABiT8tCJxWJ6+OGHdfHFF6u4uFgTJ07Uxx9/7GzfunWrJk2apIEDB6qkpETPPvtsqocAAHCplIfOE088oRdffFHz5s3T6tWr1bt3b02dOlW1tbXat2+fJk+erJ49e2rVqlW66aabNH/+fK1atSrVwwAAuJAv1Tt86623NHbsWF144YWSpDvvvFMvvviiPv74Y1VVVcnv9+vuu++Wz+dTnz59tHPnTj311FMaP358qocCAHCZlM90unbtqnfeeUe7d+9WPB7XypUrFQgEFAqFVFZWpqFDh8rn+2fWDR8+XDt27NDevXtTPRQAgMukfKYza9Ys/epXv9IPfvADeb1eZWRkaNGiRerZs6eqq6tVWFiY1D8vL0+StGfPHn33u99t1THtEAuFQic3eBewa6AWd6EWd6IWdwgEAopEIi3q67Esy0rlwV9//XUtW7ZMU6ZMUX5+vl588UW98sorev755zV9+nSNHTtWv/rVr5z+u3bt0iWXXKLly5dr8ODBrTqmZVnyeDypKgEAcIIqKyt19tlnH7dfSmc6e/bs0W233aZly5Y5AVJUVKTt27dr0aJFCgaDR6VhOByWJGVnZ7f6uDU1NSooKNCECRNUUVHR+gJcIBQKqbS0lFpchlrciVrcYc2aNS3um9LQ2bx5s6LRqIqKipLaBwwYoP/93//VGWecodra2qRt9u/5+fmtPm4sFpMkVVRUaNOmTa3ej5tQiztRiztRS3q19NSalOKFBAUFBZKkTz/9NKl927Zt6tWrl4YMGaKNGzcqHo8729avX6/evXura9euqRwKAMCFUho6/fv31wUXXKCZM2dq/fr12rFjhxYuXKh169bpl7/8pcaPH6+GhgbNmjVL27dv10svvaRly5Zp2rRpqRwGAMClUnp6LSMjQ0888YQWLlyo3/72tzpw4IAKCwu1bNkyDRgwQJK0ZMkS3XPPPRo3bpy6deumGTNmaNy4cakcBgDApVK+ZLpTp06aM2eO5syZc8zt/fv318qVK1N9WABAG8ADPwEAxhA6AABjCB0AgDGEDgDAGEIHAGAMoQMAMIbQAQAYQ+gAAIwhdAAAxhA6AABjCB0AgDGEDgDAGEIHAGAMoQMAMIbQAQAYQ+gAAIwhdAAAxhA6AABjCB0AgDGEDgDAGEIHAGAMoQMAMIbQAQAYQ+gAAIwhdAAAxhA6AABjCB0AgDGEDgDAGEIHAGCML90DANLF4/HI5/MpIyNDHo/HaWv+3RYMBp3vWVlZkiTLso653yPbY7GY4vF4SscOtFWEDk5bnTp1UnFxsbp06aJgMKhgMKiMjAxlZmbK6/U6/SzLUkFBgSTpsssu0/nnny/LshSPx2VZlizLUiKRkHQ4YOzfo9GoEomEtm/froqKCoIHEKGD01hOTo4GDRqkXr16KScnR7m5ufL7/erQoYP8fn9SX5/v8D+VUaNGaf/+/ZL+OYNJJBLO91gs5rSHw2FFo1HF43Ft27aN0AFE6OA04/F41LlzZ+Xm5uqMM85QTk6OMjMzFQwGlZ2dLb/fr+zsbAUCAWcWY1mWMjIOX/4MBoPq0KGDJDlBI0mJRMIJnWg0qlgspkOHDikSiahbt27q06ePDh06pC+//FKNjY1pqx9IN0IHpxWv16uioiINHTpUOTk56tGjhzp06KDvfOc76tKli/x+vzp27KhAIKB4PK5YLKZEIuFc4+nUqZNzfccOIq/XK6/XK4/Ho6amJjU1NSkcDquurk7hcFiDBw/WmWeeqS+//FKvvfaaduzYka7ygbQjdHBa8Xg86tSpk3r06JE0uwkEAsrMzJTf71dmZqYCgYBisZikw9d07NAJBALOfjIyMpSRkSGv1yu/3y+Px+MEkNfr1aFDhyRJXbp0USAQkM/nU8eOHeXz+ZyZEXC6IXRwWvF4PAoEAurYsaOysrKUm5urQCCgnJwc5eTkyOfzKTs7Wz6fT9FoVJKSZjr2tR07YOzwsRce+P1+J6TsGZO9Oi4ej2vYsGE688wztWvXLn366afOMYDTBaGD005mZqZycnKUlZXlXNPJzc11QicQCMjr9SojI8NZidZ8pmMHjN1HUlIo2UGUk5OjaDTq9AkEAho2bJgOHTqk999/X5WVlYQOTjuEDk4LgUBA3/nOd5Sdne2sUvP5fM6XHSBH3p/TfDGB/XsikXCCpHm/5ux7gCQ5p+/sccRisaQl2cDphNDBaSEvL0+jR49Wt27ddO655zqnvrKyshQIBJxrMpKc+2+aL3+2Q6b5ajW77chQkg7PgrKyspKu2zQ1NamhoUHRaNSZEQGnm5N6DM7ixYt19dVXJ7Vt3bpVkyZN0sCBA1VSUqJnn302aXsikdAjjzyikSNHauDAgbruuuu0a9eukxkGcFzZ2dk688wzdc4556hr167y+/3y+/1JK8+kf4aGfaHfDqDmYdPSJxHYCwyaf33TjAo4XbQ6dJYvX66FCxcmte3bt0+TJ09Wz549tWrVKt10002aP3++Vq1a5fR5/PHHVVpaqnnz5mnFihVKJBKaOnWqIpFIq4sAjscOC/tJAY2NjWpsbHSWODdf6mzf0GnPZjweT9LjcZovHrCvAWVlZTkLEOzjRCIRZ5/H2jdwOjrh02s1NTWaM2eOPvjgA/Xq1Stp2wsvvCC/36+7775bPp9Pffr00c6dO/XUU09p/PjxikQievrpp3X77bdr9OjRkqSHHnpII0eO1BtvvKGxY8emoibgmOxH14TDYTU2NioWi8nv9ztLo+0gsSzLWdZsB4yt+VLp5teF7NNziURC4XBYiURCjY2NzvdwOOyEjh083zRjAtqzE57pbNmyRX6/X2vWrNGAAQOStpWVlWno0KHOBVRJGj58uHbs2KG9e/eqoqJCBw8e1IgRI5ztubm56tu3rzZs2HASZQDfLhqNat++ffrqq6+c6yrNnx7Q/Csej39rKDS/hnPkTKj5o3BisZgTNnbQ1dXV6csvv1RDQwOhg9PSCc90SkpKVFJScsxt1dXVKiwsTGrLy8uTJO3Zs0fV1dWSpO7dux/Vx97WGnbIhUKhVu/DLewaqCW1srKyVF1drf379ysQCOiMM8446gnT9szGvp7TfAWazZ4Z2ffp2M9os59cEIlEnNlM85/j8bgOHTqkHTt2aM+ePQqHw+rXr19ansfmptflZFGLOwQCgRZfIknp6rWmpiZnaagtMzNTkpz/0rMHeGSfAwcOtPq4+fn5kqTS0tJW78NtqMWdunXr9q3bCwoKnCdSH8uRC2/SqT29LtSSfpWVlS3ql9LQCQaDR6VdOByWdHj1kP3Mqkgk4vxs97E/o6Q1ampqVFBQoAkTJqiioqLV+3GDUCik0tJSajlFvF6vzjnnHPXp00c+n8959E2PHj3Uu3dv+f1+BYPBpOs19t+dccYZ2r17t5qampSRkaGsrCwFg0HnGW3xeFz79+/XgQMHVF9fr88//1xff/21M+v5+uuvVV5err1796b1fwM3vi6tRS3usGbNmhb3TWnoFBQUqLa2NqnN/j0/P9+5YFtbW6uePXsm9Tn33HNbfVx7vxUVFdq0aVOr9+Mm1HLqfPLJJwoEAs61GK/XqzFjxujHP/6xsrOzneex+Xy+pA9vO+OMM1RXV6eGhgbncTr26bampibFYjHV1dVp37592rlzp1atWqVdu3Y514DsRQxu+YgDt70uJ4Na0utEVh+nNHSGDBmiFStWKB6PO3dcr1+/Xr1791bXrl2Vk5Ojjh076oMPPnBCp76+XuXl5Zo0aVIqhwJ8o0gkkvSPJCMjw1lk0NjYqEOHDjkr0uxwsj/OYP/+/dq3b588Ho8TTM1Dx57p1NXV6cCBAyd12hhoj1IaOuPHj9eSJUs0a9YsTZ06VZ988omWLVumuXPnSjp8LWfSpEmaP3++unTpou9973t68MEHVVBQoDFjxqRyKECLWZal8vJyNTQ0OI/EsW8Ytf/jqU+fPho1apReeOEFffbZZ5L+uXKt+aeINjU1KRqNqqGhQXV1deksC3CllIZO165dtWTJEt1zzz0aN26cunXrphkzZmjcuHFOn+nTpysWi2n27NlqamrSkCFDtHTp0qM+qREwxbIs7d69W7t37/7GPsXFxZKk999/v82d+gDc5KRC57777juqrX///lq5cuU3/o3X69Udd9yhO+6442QODQBog07q2WsAAJwIQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGNOKnQWL16sq6++Oqnt7bff1vjx41VcXKySkhLdf//9ampqcraHw2HNnTtXI0aMUHFxsW677TbV1dWdzDAAAG1Eq0Nn+fLlWrhwYVJbWVmZbr75Zv3whz/UX/7yF82ZM0evvvqq5s6d6/S566679H//939atGiR/vSnP6myslLTp09vdQEAgLbjhEOnpqZG119/vebPn69evXolbVuxYoWGDRum66+/Xr169dJFF12k3/zmN1q7dq0ikYhqamq0evVqzZ49W4MHD1b//v21YMECbdiwQZs2bUpVTQAAlzrh0NmyZYv8fr/WrFmjAQMGJG279tprNXPmzOQDZGQoGo2qoaFBGzdulCQNHz7c2d67d2/l5+drw4YNrRk/AKAN8Z3oH5SUlKikpOSY2/r27Zv0ezQa1bJly3T++eerS5cuqqmpUefOnZWZmZnULy8vT9XV1Sc6FIfPd7iMUCjU6n24hV0DtbgLtbgTtbhDIBBQJBJpUd8TDp2WisVimjFjhj777DMtX75cktTY2KhAIHBU38zMTIXD4VYfKz8/X5JUWlra6n24DbW4E7W4E7WkX2VlZYv6nZLQaWho0K9//Wt9+OGHevTRR9W/f39JUjAYPGYahsNhZWVltfp4NTU1Kigo0IQJE1RRUdHq/bhBKBRSaWkptbgMtbgTtbjDmjVrWtw35aFTW1ur6667Tl988YWWLl2qIUOGONsKCgq0f/9+RSKRpBlPbW2tM1tpjVgsJkmqqKhoNwsSqMWdqMWdqCW9WnpqTUrxzaEHDhzQNddco7q6Oi1fvjwpcCTpggsuUCKRcBYUSFJVVZVqamqO6gsAaH9SOtP54x//qF27dmnJkiXq0qWLvvzyS2dbly5dlJ+fr8svv1yzZ8/Wvffeq6ysLM2ZM0dDhw7VwIEDUzkUAIALpSx04vG4Xn31VUWjUV1zzTVHbf+f//kf9ejRQ/PmzdO9996rm2++WZI0atQozZ49O1XDAAC42EmFzn333ef87PV69cknnxz3b7Kzs/WHP/xBf/jDH07m0ACANogHfgIAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMAYQgcAYAyhAwAw5qRCZ/Hixbr66qu/cfvs2bNVUlKS1JZIJPTII49o5MiRGjhwoK677jrt2rXrZIYBAGgjWh06y5cv18KFC79x+1tvvaUXX3zxqPbHH39cpaWlmjdvnlasWKFEIqGpU6cqEom0digAgDbihEOnpqZG119/vebPn69evXods09tba1+97vfaejQoUntkUhETz/9tKZPn67Ro0crFArpoYceUnV1td54441WFQAAaDtOOHS2bNkiv9+vNWvWaMCAAUdttyxLd955p3784x8fFToVFRU6ePCgRowY4bTl5uaqb9++2rBhQyuGDwBoS3wn+gclJSVHXadpbtmyZfryyy/15JNPavHixUnbqqurJUndu3dPas/Ly3O2tYbPd7iMUCjU6n24hV0DtbgLtbgTtbhDIBBo8SWSEw6db1NRUaFHH31Uy5cvVyAQOGp7Y2OjM8DmMjMzdeDAgVYfNz8/X5JUWlra6n24DbW4E7W4E7WkX2VlZYv6pSx0wuGwbr/9dt1www3fmNTBYFDS4Ws79s/232ZlZbX62DU1NSooKNCECRNUUVHR6v24QSgUUmlpKbW4DLW4E7W4w5o1a1rcN2Whs3nzZn322Wd69NFH9dhjj0mSotGoYrGYiouL9R//8R/OabXa2lr17NnT+dva2lqde+65rT52LBaTdHimtWnTppOowj2oxZ2oxZ2oJb1OZPVxykKnf//+R61Ae+655/TGG2/oueeeU35+vjIyMtSxY0d98MEHTujU19ervLxckyZNStVQAAAulbLQCQaDOuuss5LaOnXqJJ/Pl9Q+adIkzZ8/X126dNH3vvc9PfjggyooKNCYMWNSNRQAgEuldCFBS0yfPl2xWEyzZ89WU1OThgwZoqVLl8rv95seCgDAsJMKnfvuu+9bt99yyy265ZZbktq8Xq/uuOMO3XHHHSdzaABAG8QDPwEAxhA6AABjCB0AgDGEDgDAGI9lWVa6B3GyYrGYfD6fdu/e3eY/IiEQCKhHjx7U4jLU4k7U4g5nnnmmYrFYi54s0y5CBwDQNnB6DQBgDKEDADCG0AEAGEPoAACMIXQAAMYQOgAAYwgdAIAxhA4AwBhCBwBgDKEDADCG0AEAGEPoAACMadOhk0gk9Mgjj2jkyJEaOHCgrrvuOu3atSvdw2qR/fv36/e//71GjRqlQYMG6aqrrlJZWZmzfd26dbryyis1YMAAXXrppXrllVfSONqWq6qqUnFxsV566SWnbevWrZo0aZIGDhyokpISPfvss2kc4fGtXr1al112mYqKinT55Zfrtddec7bt3r1b06ZN06BBg3ThhRdq4cKFisfjaRztN4vFYnr44Yd18cUXq7i4WBMnTtTHH3/sbG8rr8vixYt19dVXJ7Udb+xufW84Vi1vv/22xo8fr+LiYpWUlOj+++9XU1OTsz0cDmvu3LkaMWKEiouLddttt6murs700FPHasMWLVpkDRs2zHrnnXesrVu3Wtdee601ZswYKxwOp3toxzV58mRr7Nix1oYNG6zKykpr7ty5Vv/+/a3PP//c2r59u1VUVGQtWLDA2r59u7VkyRKrb9++1vvvv5/uYX+rSCRiXXnllVZhYaG1atUqy7Isq66uzho2bJj129/+1tq+fbv15z//2SoqKrL+/Oc/p3m0x7Z69Wqrb9++1vPPP2/t3LnTevzxx61QKGR99NFHViQSscaMGWP98pe/tD799FPrzTfftIYOHWo9/PDD6R72MT3yyCPW97//feuvf/2rtWPHDmvWrFnWBRdcYNXU1LSZ1+X555+3QqGQNWnSJKetJWN343vDsWrZsGGDdd5551lPPPGEVVVVZb377rvWqFGjrDvvvNPpc+edd1qXXHKJtWHDBmvz5s3Wv/zLv1gTJ05MRwkp0WZDJxwOW8XFxdby5cudtgMHDlj9+/e31q5dm8aRHd+OHTuswsJCq6yszGlLJBLWJZdcYi1cuND63e9+Z/3kJz9J+ptbb73Vuvbaa00P9YT8+7//u/Xzn/88KXSefPJJ68ILL7Si0WhSvzFjxqRrmN8okUhYF198sXXfffcltV977bXWk08+aa1du9Y6//zzrf379zvbVqxYYQ0aNMiV/6Hzox/9yPrjH//o/P71119bhYWF1uuvv+7616W6utqaNm2aNXDgQOvSSy9NeqM+3tjd9t7wbbXcdttt1i9+8Yuk/n/5y1+sfv36WeFw2KqurrZCoZD17rvvOtsrKyutwsJC66OPPjJWQyq12dNrFRUVOnjwoEaMGOG05ebmqm/fvtqwYUMaR3Z8nTt31lNPPaWioiKnzePxyOPxqL6+XmVlZUl1SdLw4cO1ceNGWS79+KMNGzZo5cqVuu+++5Lay8rKNHToUPl8Pqdt+PDh2rFjh/bu3Wt6mN+qqqpKX3zxha644oqk9qVLl2ratGkqKytTv3791KlTJ2fb8OHD1dDQoK1bt5oe7nF17dpV77zzjnbv3q14PK6VK1cqEAgoFAq5/nXZsmWL/H6/1qxZowEDBiRtO97Y3fbe8G21XHvttZo5c2ZSW0ZGhqLRqBoaGrRx40ZJh+uz9e7dW/n5+a5/n/smbTZ0qqurJUndu3dPas/Ly3O2uVVubq4uuugiBQIBp+3111/Xzp07NXLkSFVXV6ugoCDpb/Ly8tTY2Kh9+/aZHu5x1dfXa8aMGZo9e/ZRr8c31SJJe/bsMTbGlqiqqpIkHTp0SFOmTNGIESP005/+VG+//baktlWLJM2aNUt+v18/+MEPVFRUpIceekiPPPKIevbs6fpaSkpKtGjRIp155plHbTve2N323vBttfTt21ehUMj5PRqNatmyZTr//PPVpUsX1dTUqHPnzsrMzEz6u7bwPvdN2mzoNDY2SlLSG7ckZWZmKhwOp2NIrfbRRx/pt7/9rcaMGaPRo0erqanpqLrs3934MbZ33XWXiouLj5ohSDpmLfY/ILe9Tg0NDZKkmTNnauzYsXr66af1/e9/XzfeeKPWrVvXpmqRpO3btysnJ0ePPfaYVq5cqSuvvFK33367tm7d2uZqae54Y2+r7w2xWEwzZszQZ599pjlz5kg6/D53ZB2S+2v5Nr7jd3GnYDAo6fCbsP2zdPj/dC35nG63eOutt3T77bdr0KBBmj9/vqTD/4c6Mlzs391W2+rVq1VWVqa1a9cec3swGDyqFvsfS3Z29ikf34nw+/2SpClTpmjcuHGSpPPOO0/l5eV65pln2lQte/bs0W233aZly5Zp8ODBkqSioiJt375dixYtalO1HOl4Y2+L7w0NDQ369a9/rQ8//FCPPvqo+vfvL+nYtUruruV42uxMx54619bWJrXX1tYqPz8/HUM6Yc8//7xuueUWXXzxxXryySed/1rr3r37MevKzs5WTk5OOob6jVatWqWvvvpKo0ePVnFxsYqLiyVJc+bM0dSpU1VQUHDMWiS57nWyx1NYWJjUfs4552j37t1tqpbNmzcrGo0mXTeUpAEDBmjnzp1tqpYjHW/sbe29oba21lnOvnTpUl100UXOtoKCAu3fv/+o4HFrLS3RZkMnFAqpY8eO+uCDD5y2+vp6lZeXa8iQIWkcWcuUlpZq3rx5mjhxohYsWJA0hR48eLA+/PDDpP7r16/XoEGDlJHhrpds/vz5evXVV7V69WrnS5KmT5+ue+65R0OGDNHGjRuT7mVZv369evfura5du6Zp1MfWr18/dejQQZs3b05q37Ztm3r27KkhQ4aovLzcOQ0nHa6lQ4cOSefl3cC+5vHpp58mtW/btk29evVqU6/LkY439rb03nDgwAFdc801qqur0/Lly48a3wUXXKBEIuEsKJAOX3usqalxXS0tlu7lcydjwYIF1tChQ6233noraS1+JBJJ99C+VWVlpdWvXz/rpptusmpra5O+6uvrrW3btln9+vWzHnzwQWv79u3W0qVL28R9OrbmS6b37t1rDRkyxJo5c6b12WefWatWrbKKioqsl156Kc2jPLbHHnvMKi4uttauXZt0n8769eutpqYm65JLLrGmTJlibd261blPZ9GiReke9lHi8bh11VVXWZdeeqm1bt06q6qqynrooYes8847z/r444/b1Osyc+bMpGXGLRm7W98bjqxl5syZVr9+/ax169Yd9V4Qi8Usyzp8u0RJSYm1fv165z6d5vtoa9p06MRiMeuBBx6whg8fbg0cONC67rrrrF27dqV7WMf1xBNPWIWFhcf8mjlzpmVZlvXee+9ZY8eOtc4//3zr0ksvtV555ZU0j7rlmoeOZVnW5s2brZ/97GfW+eefb1188cXWc889l8bRHd/TTz9tlZSUWP369bN+9KMfWW+++aazbceOHdbkyZOtoqIi68ILL7QWLlxoxePxNI72m+3fv9+66667rNGjR1vFxcXWv/7rv1offPCBs72tvC5HvlFb1vHH7tb3hua1xGIxq6io6BvfC+zxHjx40Jo1a5Y1ePBga/Dgwdatt95q1dXVpbOMk+KxLJfe+AEAaHfcdYEAANCuEToAAGMIHQCAMYQOAMAYQgcAYAyhAwAwhtABABhD6AAAjCF0AADGEDoAAGMIHQCAMYQOAMCY/wfjLhc2jzfnQAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 14\n",
    "\n",
    "print(train_data['Image_Path'][i])\n",
    "image = rgb2hsv(skimage.io.imread(train_data['Image_Path'][i]))\n",
    "print(np.max(image))\n",
    "result = ((image > 0.5)*image)[..., 1]\n",
    "plt.imshow(result, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20601/20601 [00:15<00:00, 1356.70it/s]\n",
      "100%|██████████| 2943/2943 [00:02<00:00, 1293.60it/s]\n",
      "100%|██████████| 2617/2617 [00:02<00:00, 1218.91it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "train_data['image_arr'] = train_data['Image_Path'].progress_apply(lambda x: read_image(x))\n",
    "val_data['image_arr']   = val_data['Image_Path'].progress_apply(lambda x: read_image(x))\n",
    "test_data['image_arr']  = test_data['Image_Path'].progress_apply(lambda x: read_image(x))\n",
    "\n",
    "\n",
    "x_train, y_train = train_data['image_arr'].to_numpy(), train_data['Parasitized'].to_numpy()\n",
    "x_val  , y_val   = val_data['image_arr'].to_numpy()  , val_data['Parasitized'].to_numpy()\n",
    "x_test , y_test  = test_data['image_arr'].to_numpy() , test_data['Parasitized'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20601it [00:21, 946.82it/s]\n"
     ]
    }
   ],
   "source": [
    "augment = A.augmentations.geometric.transforms.Affine(\n",
    "    translate_percent = 0.1,\n",
    "    rotate = 60,\n",
    "    shear = 30\n",
    "    )\n",
    "\n",
    "augment = A.ShiftScaleRotate(scale_limit = (-0.5, 0.01),rotate_limit= 180, border_mode=cv2.BORDER_CONSTANT, always_apply= True)\n",
    "\n",
    "transform = A.Compose(\n",
    "    [augment,\n",
    "    A.VerticalFlip(p = 0.5),\n",
    "    A.HorizontalFlip(p = 0.5),\n",
    "    A.augmentations.geometric.Affine(shear = 30),\n",
    "    A.Resize(HEIGHT, WIDTH, always_apply= True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "aug_dataset = []\n",
    "aug_labels = []\n",
    "COPIES = 3\n",
    "\n",
    "for i, lab in tqdm(zip(x_train, y_train)):\n",
    "    for _ in range(COPIES):\n",
    "        aug_dataset.append(transform(image = i)['image'])\n",
    "        aug_labels.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_aug = np.array(aug_dataset)\n",
    "y_train_aug = np.array(aug_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20601/20601 [00:19<00:00, 1048.81it/s]\n",
      "100%|██████████| 2943/2943 [00:02<00:00, 1125.43it/s]\n",
      "100%|██████████| 2617/2617 [00:02<00:00, 1131.18it/s]\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "for img in tqdm(x_train):\n",
    "    temp.append(resize(img, (HEIGHT, WIDTH)))\n",
    "x_train = np.array(temp)\n",
    "\n",
    "\n",
    "temp = []\n",
    "for img in tqdm(x_val):\n",
    "    temp.append(resize(img, (HEIGHT, WIDTH)))\n",
    "x_val = np.array(temp)\n",
    "\n",
    "\n",
    "temp = []\n",
    "for img in tqdm(x_test):\n",
    "    temp.append(resize(img, (HEIGHT, WIDTH)))\n",
    "x_test = np.array(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_pickle(\"x_train_aug\", x_train_aug)\n",
    "compressed_pickle(\"y_train_aug\", y_train_aug)\n",
    "compressed_pickle(\"x_train\", x_train)\n",
    "compressed_pickle(\"y_train\", y_train)\n",
    "compressed_pickle(\"x_val\", x_val)\n",
    "compressed_pickle(\"y_val\", y_val)\n",
    "compressed_pickle(\"x_test\", x_test)\n",
    "compressed_pickle(\"y_test\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented:  (61803, 25, 25, 3) (61803,)\n",
      "train:  (20601, 25, 25, 3) (20601,)\n",
      "val:  (2943, 25, 25, 3) (2943,)\n",
      "test:  (2617, 25, 25, 3) (2617,)\n"
     ]
    }
   ],
   "source": [
    "x_train_aug = decompress_pickle(SAVE_DIR + 'x_train_aug.pbz2')\n",
    "y_train_aug = decompress_pickle(SAVE_DIR + 'y_train_aug.pbz2')\n",
    "x_train = decompress_pickle(SAVE_DIR + 'x_train.pbz2')\n",
    "y_train = decompress_pickle(SAVE_DIR + 'y_train.pbz2')\n",
    "x_val = decompress_pickle(SAVE_DIR + 'x_val.pbz2')\n",
    "y_val = decompress_pickle(SAVE_DIR + 'y_val.pbz2')\n",
    "x_test = decompress_pickle(SAVE_DIR + 'x_test.pbz2')\n",
    "y_test = decompress_pickle(SAVE_DIR + 'y_test.pbz2')\n",
    "\n",
    "print(\"augmented: \", x_train_aug.shape, y_train_aug.shape)\n",
    "print(\"train: \", x_train.shape, y_train.shape)\n",
    "print(\"val: \", x_val.shape, y_val.shape)\n",
    "print(\"test: \", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_aug_train = x_train_aug.shape[0]\n",
    "n_train     = x_train.shape[0]\n",
    "n_val       = x_val.shape[0]\n",
    "n_test      = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DIGITS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unaugmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.611     0.746     0.672     10260\n",
      "         1.0      0.677     0.530     0.594     10341\n",
      "\n",
      "    accuracy                          0.637     20601\n",
      "   macro avg      0.644     0.638     0.633     20601\n",
      "weighted avg      0.644     0.637     0.633     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.620     0.761     0.683      1466\n",
      "         1.0      0.693     0.538     0.606      1477\n",
      "\n",
      "    accuracy                          0.649      2943\n",
      "   macro avg      0.657     0.649     0.644      2943\n",
      "weighted avg      0.657     0.649     0.644      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.613     0.766     0.681      1303\n",
      "         1.0      0.692     0.521     0.595      1314\n",
      "\n",
      "    accuracy                          0.643      2617\n",
      "   macro avg      0.653     0.644     0.638      2617\n",
      "weighted avg      0.653     0.643     0.638      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "nb_cls = naive_bayes.GaussianNB()\n",
    "nb_cls.fit(x_train.reshape(n_train, -1), y_train)\n",
    "preds_train = nb_cls.predict(x_train.reshape(n_train, -1))\n",
    "preds_val   = nb_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = nb_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n",
    "# eval = testing_module.ModelEvaluation(y_val, \n",
    "#     nb_cls.predict(x_val.reshape(n_val, -1)),\n",
    "#     model_reference_name = 'Naive Bayes',\n",
    "#     model_type = 'classification',\n",
    "#     plot_classification_metric = ['roc_auc']) # if classification\n",
    "# eval.evaluate(evaluate_save= True, plots_show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 43 seconds\n",
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.729     0.754     0.741     10260\n",
      "         1.0      0.747     0.722     0.734     10341\n",
      "\n",
      "    accuracy                          0.738     20601\n",
      "   macro avg      0.738     0.738     0.738     20601\n",
      "weighted avg      0.738     0.738     0.738     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.693     0.715     0.704      1466\n",
      "         1.0      0.708     0.685     0.696      1477\n",
      "\n",
      "    accuracy                          0.700      2943\n",
      "   macro avg      0.700     0.700     0.700      2943\n",
      "weighted avg      0.700     0.700     0.700      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.689     0.738     0.713      1303\n",
      "         1.0      0.721     0.670     0.694      1314\n",
      "\n",
      "    accuracy                          0.704      2617\n",
      "   macro avg      0.705     0.704     0.704      2617\n",
      "weighted avg      0.705     0.704     0.704      2617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   42.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_cls =  LogisticRegression(max_iter = 200, verbose = 10, n_jobs = -1, solver = 'saga')\n",
    "logreg_cls.fit(x_train.reshape(n_train, -1), y_train)\n",
    "preds_train = logreg_cls.predict(x_train.reshape(n_train, -1))\n",
    "preds_val   = logreg_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = logreg_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n",
    "# eval = testing_module.ModelEvaluation(y_val, \n",
    "#     nb_cls.predict(x_val.reshape(n_val, -1)),\n",
    "#     model_reference_name = 'Naive Bayes',\n",
    "#     model_type = 'classification',\n",
    "#     plot_classification_metric = ['roc_auc']) # if classification\n",
    "# eval.evaluate(evaluate_save= True, plots_show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.685     0.774     0.727     10260\n",
      "         1.0      0.743     0.646     0.691     10341\n",
      "\n",
      "    accuracy                          0.710     20601\n",
      "   macro avg      0.714     0.710     0.709     20601\n",
      "weighted avg      0.714     0.710     0.709     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.677     0.774     0.722      1466\n",
      "         1.0      0.738     0.633     0.681      1477\n",
      "\n",
      "    accuracy                          0.703      2943\n",
      "   macro avg      0.707     0.703     0.702      2943\n",
      "weighted avg      0.707     0.703     0.702      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.661     0.748     0.702      1303\n",
      "         1.0      0.713     0.620     0.663      1314\n",
      "\n",
      "    accuracy                          0.684      2617\n",
      "   macro avg      0.687     0.684     0.683      2617\n",
      "weighted avg      0.687     0.684     0.683      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_cls =  DecisionTreeClassifier(criterion = 'gini', splitter = 'best', max_depth = 5, min_samples_split = 2, )\n",
    "dt_cls.fit(x_train.reshape(n_train, -1), y_train)\n",
    "preds_train = dt_cls.predict(x_train.reshape(n_train, -1))\n",
    "preds_val   = dt_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = dt_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n",
    "# eval = testing_module.ModelEvaluation(y_val, \n",
    "#     nb_cls.predict(x_val.reshape(n_val, -1)),\n",
    "#     model_reference_name = 'Naive Bayes',\n",
    "#     model_type = 'classification',\n",
    "#     plot_classification_metric = ['roc_auc']) # if classification\n",
    "# eval.evaluate(evaluate_save= True, plots_show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.966     0.983     0.974     10260\n",
      "         1.0      0.983     0.966     0.974     10341\n",
      "\n",
      "    accuracy                          0.974     20601\n",
      "   macro avg      0.974     0.974     0.974     20601\n",
      "weighted avg      0.975     0.974     0.974     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.842     0.873     0.857      1466\n",
      "         1.0      0.869     0.837     0.853      1477\n",
      "\n",
      "    accuracy                          0.855      2943\n",
      "   macro avg      0.855     0.855     0.855      2943\n",
      "weighted avg      0.855     0.855     0.855      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.842     0.861     0.851      1303\n",
      "         1.0      0.859     0.839     0.849      1314\n",
      "\n",
      "    accuracy                          0.850      2617\n",
      "   macro avg      0.850     0.850     0.850      2617\n",
      "weighted avg      0.850     0.850     0.850      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_cls = XGBClassifier(max_depth = 5, objective = 'reg:logistic',\n",
    "                            num_parallel_tree = 20, booster = 'gbtree',\n",
    "                            gamma = 0.5, tree_method = 'gpu_hist', subsample = 0.4, reg_lambda = 1)\n",
    "xgb_cls.fit(x_train.reshape(n_train, -1), y_train)\n",
    "preds_train = xgb_cls.predict(x_train.reshape(n_train, -1))\n",
    "preds_val   = xgb_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = xgb_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=250).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.456     0.498     0.476     10260\n",
      "         1.0      0.452     0.411     0.430     10341\n",
      "\n",
      "    accuracy                          0.454     20601\n",
      "   macro avg      0.454     0.454     0.453     20601\n",
      "weighted avg      0.454     0.454     0.453     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.446     0.477     0.461      1466\n",
      "         1.0      0.442     0.412     0.426      1477\n",
      "\n",
      "    accuracy                          0.444      2943\n",
      "   macro avg      0.444     0.444     0.444      2943\n",
      "weighted avg      0.444     0.444     0.444      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.457     0.486     0.471      1303\n",
      "         1.0      0.456     0.428     0.441      1314\n",
      "\n",
      "    accuracy                          0.457      2617\n",
      "   macro avg      0.457     0.457     0.456      2617\n",
      "weighted avg      0.457     0.457     0.456      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_cls = SVC(kernel = 'rbf', max_iter = 250, verbose= True)\n",
    "svm_cls.fit(x_train.reshape(n_train, -1), y_train)\n",
    "preds_train = svm_cls.predict(x_train.reshape(n_train, -1))\n",
    "preds_val   = svm_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = svm_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "322/322 [==============================] - 9s 17ms/step - loss: 0.2166 - accuracy: 0.9174 - val_loss: 0.1312 - val_accuracy: 0.9521\n",
      "Epoch 2/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.1290 - accuracy: 0.9501 - val_loss: 0.1222 - val_accuracy: 0.9524\n",
      "Epoch 3/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.1127 - accuracy: 0.9562 - val_loss: 0.1166 - val_accuracy: 0.9602\n",
      "Epoch 4/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.1048 - accuracy: 0.9585 - val_loss: 0.1190 - val_accuracy: 0.9562\n",
      "Epoch 5/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.0942 - accuracy: 0.9632 - val_loss: 0.1140 - val_accuracy: 0.9572\n",
      "Epoch 6/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.0860 - accuracy: 0.9660 - val_loss: 0.1030 - val_accuracy: 0.9640\n",
      "Epoch 7/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.0856 - accuracy: 0.9673 - val_loss: 0.1080 - val_accuracy: 0.9626\n",
      "Epoch 8/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.0775 - accuracy: 0.9707 - val_loss: 0.1270 - val_accuracy: 0.9667\n",
      "Epoch 9/50\n",
      "322/322 [==============================] - 5s 15ms/step - loss: 0.0720 - accuracy: 0.9732 - val_loss: 0.1254 - val_accuracy: 0.9589\n",
      "644/644 [==============================] - 5s 7ms/step\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "82/82 [==============================] - 1s 7ms/step\n",
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.967     0.981     0.974     10260\n",
      "         1.0      0.981     0.966     0.974     10341\n",
      "\n",
      "    accuracy                          0.974     20601\n",
      "   macro avg      0.974     0.974     0.974     20601\n",
      "weighted avg      0.974     0.974     0.974     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.954     0.964     0.959      1466\n",
      "         1.0      0.964     0.954     0.959      1477\n",
      "\n",
      "    accuracy                          0.959      2943\n",
      "   macro avg      0.959     0.959     0.959      2943\n",
      "weighted avg      0.959     0.959     0.959      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.946     0.964     0.955      1303\n",
      "         1.0      0.964     0.946     0.955      1314\n",
      "\n",
      "    accuracy                          0.955      2617\n",
      "   macro avg      0.955     0.955     0.955      2617\n",
      "weighted avg      0.955     0.955     0.955      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagenet = tf.keras.applications.Xception(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = (72, 72, 3)\n",
    ")\n",
    "imagenet.trainable = False\n",
    "\n",
    "trans_learn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(72, 72),\n",
    "    imagenet,\n",
    "\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "trans_learn.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = trans_learn.fit(\n",
    "            x_train, y_train, batch_size = 64,\n",
    "            shuffle = True,\n",
    "            epochs = 50,\n",
    "            validation_data = [x_val, y_val],\n",
    "            validation_batch_size = 32,\n",
    "            callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "        )\n",
    "preds_train = np.argmax(trans_learn.predict(x_train), axis = 1)\n",
    "preds_val   = np.argmax(trans_learn.predict(x_val), axis = 1)\n",
    "preds_test  = np.argmax(trans_learn.predict(x_test), axis = 1)\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 17ms/step - loss: 0.7031 - accuracy: 0.5248 - val_loss: 0.6811 - val_accuracy: 0.6174\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6667 - accuracy: 0.6009 - val_loss: 0.6539 - val_accuracy: 0.6069\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6201 - accuracy: 0.6575 - val_loss: 0.6843 - val_accuracy: 0.5790\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.5892 - accuracy: 0.6901 - val_loss: 0.4957 - val_accuracy: 0.7788\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.5119 - accuracy: 0.7567 - val_loss: 0.4690 - val_accuracy: 0.8029\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.4793 - accuracy: 0.7806 - val_loss: 0.4648 - val_accuracy: 0.7829\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.8139 - val_loss: 0.3688 - val_accuracy: 0.8522\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.3646 - accuracy: 0.8469 - val_loss: 0.2899 - val_accuracy: 0.8804\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.2738 - accuracy: 0.8935 - val_loss: 0.2147 - val_accuracy: 0.9198\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.2032 - accuracy: 0.9248 - val_loss: 0.1889 - val_accuracy: 0.9310\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.1622 - accuracy: 0.9407 - val_loss: 0.1241 - val_accuracy: 0.9521\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.1450 - accuracy: 0.9480 - val_loss: 0.1198 - val_accuracy: 0.9562\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.1199 - accuracy: 0.9563 - val_loss: 0.0960 - val_accuracy: 0.9681\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0890 - accuracy: 0.9680 - val_loss: 0.0791 - val_accuracy: 0.9711\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0754 - accuracy: 0.9731 - val_loss: 0.0742 - val_accuracy: 0.9738\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0741 - accuracy: 0.9741 - val_loss: 0.0868 - val_accuracy: 0.9684\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0752 - accuracy: 0.9737 - val_loss: 0.0555 - val_accuracy: 0.9806\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0579 - accuracy: 0.9794 - val_loss: 0.0639 - val_accuracy: 0.9762\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0527 - accuracy: 0.9816 - val_loss: 0.0508 - val_accuracy: 0.9844\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0482 - accuracy: 0.9833 - val_loss: 0.0547 - val_accuracy: 0.9834\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0466 - accuracy: 0.9842 - val_loss: 0.0526 - val_accuracy: 0.9813\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 0.0444 - val_accuracy: 0.9840\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9875 - val_loss: 0.0445 - val_accuracy: 0.9867\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9877 - val_loss: 0.0413 - val_accuracy: 0.9871\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9898 - val_loss: 0.0414 - val_accuracy: 0.9878\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0375 - val_accuracy: 0.9891\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.0425 - val_accuracy: 0.9874\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.0444 - val_accuracy: 0.9878\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9886 - val_loss: 0.0429 - val_accuracy: 0.9871\n",
      "644/644 [==============================] - 1s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "82/82 [==============================] - 0s 1ms/step\n",
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.986     0.999     0.992     10260\n",
      "         1.0      0.999     0.986     0.992     10341\n",
      "\n",
      "    accuracy                          0.992     20601\n",
      "   macro avg      0.992     0.992     0.992     20601\n",
      "weighted avg      0.992     0.992     0.992     20601\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.979     0.996     0.987      1466\n",
      "         1.0      0.996     0.978     0.987      1477\n",
      "\n",
      "    accuracy                          0.987      2943\n",
      "   macro avg      0.987     0.987     0.987      2943\n",
      "weighted avg      0.987     0.987     0.987      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.969     0.997     0.983      1303\n",
      "         1.0      0.997     0.968     0.982      1314\n",
      "\n",
      "    accuracy                          0.982      2617\n",
      "   macro avg      0.983     0.982     0.982      2617\n",
      "weighted avg      0.983     0.982     0.982      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), padding = 'same', activation = 'relu', input_shape = x_train[0].shape),\n",
    "    tf.keras.layers.MaxPool2D((3,3), padding = 'same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (2,2), padding = 'same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2), padding = 'same'),\n",
    "\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cnn.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = cnn.fit(\n",
    "            x_train, y_train, batch_size = 1024,\n",
    "            epochs = 50,\n",
    "            validation_data = [x_val, y_val],\n",
    "            validation_batch_size = 256,\n",
    "            callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "        )\n",
    "preds_train = np.argmax(cnn.predict(x_train), axis = 1)\n",
    "preds_val   = np.argmax(cnn.predict(x_val), axis = 1)\n",
    "preds_test  = np.argmax(cnn.predict(x_test), axis = 1)\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.598     0.689     0.640     30780\n",
      "         1.0      0.636     0.539     0.584     31023\n",
      "\n",
      "    accuracy                          0.614     61803\n",
      "   macro avg      0.617     0.614     0.612     61803\n",
      "weighted avg      0.617     0.614     0.612     61803\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.571     0.003     0.005      1466\n",
      "         1.0      0.502     0.998     0.668      1477\n",
      "\n",
      "    accuracy                          0.502      2943\n",
      "   macro avg      0.537     0.500     0.337      2943\n",
      "weighted avg      0.537     0.502     0.338      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.750     0.002     0.005      1303\n",
      "         1.0      0.502     0.999     0.669      1314\n",
      "\n",
      "    accuracy                          0.503      2617\n",
      "   macro avg      0.626     0.501     0.337      2617\n",
      "weighted avg      0.626     0.503     0.338      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "nb_cls = naive_bayes.GaussianNB()\n",
    "nb_cls.fit(x_train_aug.reshape(n_aug_train, -1), y_train_aug)\n",
    "preds_train = nb_cls.predict(x_train_aug.reshape(n_aug_train, -1))\n",
    "preds_val   = nb_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = nb_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 132 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.669     0.740     0.703     30780\n",
      "         1.0      0.712     0.636     0.672     31023\n",
      "\n",
      "    accuracy                          0.688     61803\n",
      "   macro avg      0.690     0.688     0.687     61803\n",
      "weighted avg      0.690     0.688     0.687     61803\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.677     0.641     0.659      1466\n",
      "         1.0      0.662     0.697     0.679      1477\n",
      "\n",
      "    accuracy                          0.669      2943\n",
      "   macro avg      0.669     0.669     0.669      2943\n",
      "weighted avg      0.669     0.669     0.669      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.677     0.617     0.646      1303\n",
      "         1.0      0.651     0.708     0.678      1314\n",
      "\n",
      "    accuracy                          0.663      2617\n",
      "   macro avg      0.664     0.662     0.662      2617\n",
      "weighted avg      0.664     0.663     0.662      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_cls =  LogisticRegression(max_iter = 200, verbose = 10, n_jobs = -1, solver = 'saga')\n",
    "logreg_cls.fit(x_train_aug.reshape(n_aug_train, -1), y_train_aug)\n",
    "preds_train = logreg_cls.predict(x_train_aug.reshape(n_aug_train, -1))\n",
    "preds_val   = logreg_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = logreg_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.669     0.763     0.713     30780\n",
      "         1.0      0.727     0.625     0.672     31023\n",
      "\n",
      "    accuracy                          0.694     61803\n",
      "   macro avg      0.698     0.694     0.692     61803\n",
      "weighted avg      0.698     0.694     0.692     61803\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000      1466\n",
      "         1.0      0.502     1.000     0.668      1477\n",
      "\n",
      "    accuracy                          0.502      2943\n",
      "   macro avg      0.251     0.500     0.334      2943\n",
      "weighted avg      0.252     0.502     0.335      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000      1303\n",
      "         1.0      0.502     1.000     0.669      1314\n",
      "\n",
      "    accuracy                          0.502      2617\n",
      "   macro avg      0.251     0.500     0.334      2617\n",
      "weighted avg      0.252     0.502     0.336      2617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_cls =  DecisionTreeClassifier(criterion = 'gini', splitter = 'best', max_depth = 20, min_samples_split = 2, )\n",
    "dt_cls.fit(x_train_aug.reshape(n_aug_train, -1), y_train_aug)\n",
    "preds_train = dt_cls.predict(x_train_aug.reshape(n_aug_train, -1))\n",
    "preds_val   = dt_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = dt_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n",
    "# eval = testing_module.ModelEvaluation(y_val, \n",
    "#     nb_cls.predict(x_val.reshape(n_val, -1)),\n",
    "#     model_reference_name = 'Naive Bayes',\n",
    "#     model_type = 'classification',\n",
    "#     plot_classification_metric = ['roc_auc']) # if classification\n",
    "# eval.evaluate(evaluate_save= True, plots_show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.836     0.904     0.869     30780\n",
      "         1.0      0.897     0.824     0.859     31023\n",
      "\n",
      "    accuracy                          0.864     61803\n",
      "   macro avg      0.866     0.864     0.864     61803\n",
      "weighted avg      0.867     0.864     0.864     61803\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000      1466\n",
      "         1.0      0.502     1.000     0.668      1477\n",
      "\n",
      "    accuracy                          0.502      2943\n",
      "   macro avg      0.251     0.500     0.334      2943\n",
      "weighted avg      0.252     0.502     0.335      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000      1303\n",
      "         1.0      0.502     1.000     0.669      1314\n",
      "\n",
      "    accuracy                          0.502      2617\n",
      "   macro avg      0.251     0.500     0.334      2617\n",
      "weighted avg      0.252     0.502     0.336      2617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_cls = XGBClassifier(max_depth = 5, objective = 'reg:logistic',\n",
    "                            num_parallel_tree = 20, booster = 'gbtree',\n",
    "                            gamma = 0.5, tree_method = 'gpu_hist', subsample = 0.4, reg_lambda = 1)\n",
    "xgb_cls.fit(x_train_aug.reshape(n_aug_train, -1), y_train_aug)\n",
    "preds_train = xgb_cls.predict(x_train_aug.reshape(n_aug_train, -1))\n",
    "preds_val   = xgb_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = xgb_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=250).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.508     0.633     0.564     30780\n",
      "         1.0      0.518     0.392     0.446     31023\n",
      "\n",
      "    accuracy                          0.512     61803\n",
      "   macro avg      0.513     0.512     0.505     61803\n",
      "weighted avg      0.513     0.512     0.505     61803\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000      1466\n",
      "         1.0      0.502     1.000     0.668      1477\n",
      "\n",
      "    accuracy                          0.502      2943\n",
      "   macro avg      0.251     0.500     0.334      2943\n",
      "weighted avg      0.252     0.502     0.335      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000      1303\n",
      "         1.0      0.502     1.000     0.669      1314\n",
      "\n",
      "    accuracy                          0.502      2617\n",
      "   macro avg      0.251     0.500     0.334      2617\n",
      "weighted avg      0.252     0.502     0.336      2617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_cls = SVC(kernel = 'rbf', max_iter = 250, verbose= True)\n",
    "svm_cls.fit(x_train_aug.reshape(n_aug_train, -1), y_train_aug)\n",
    "preds_train = svm_cls.predict(x_train_aug.reshape(n_aug_train, -1))\n",
    "preds_val   = svm_cls.predict(x_val.reshape(n_val, -1))\n",
    "preds_test  = svm_cls.predict(x_test.reshape(n_test, -1))\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "483/483 [==============================] - 14s 25ms/step - loss: 0.6566 - accuracy: 0.6789 - val_loss: 0.6932 - val_accuracy: 0.5019\n",
      "Epoch 2/50\n",
      "181/483 [==========>...................] - ETA: 6s - loss: 0.5643 - accuracy: 0.7162"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 24\u001b[0m\n\u001b[0;32m      8\u001b[0m trans_learn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      9\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mResizing(\u001b[38;5;241m72\u001b[39m, \u001b[38;5;241m72\u001b[39m),\n\u001b[0;32m     10\u001b[0m     imagenet,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m2\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m ])\n\u001b[0;32m     18\u001b[0m trans_learn\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     19\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),\n\u001b[0;32m     20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     22\u001b[0m )\n\u001b[1;32m---> 24\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrans_learn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx_train_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m preds_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(trans_learn\u001b[38;5;241m.\u001b[39mpredict(x_train_aug), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m preds_val   \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(trans_learn\u001b[38;5;241m.\u001b[39mpredict(x_val), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "imagenet = tf.keras.applications.Xception(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = (72, 72, 3)\n",
    ")\n",
    "imagenet.trainable = False\n",
    "\n",
    "trans_learn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(72, 72),\n",
    "    imagenet,\n",
    "\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "trans_learn.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = trans_learn.fit(\n",
    "            x_train_aug, y_train_aug, batch_size = 128,\n",
    "            shuffle = True,\n",
    "            epochs = 50,\n",
    "            validation_data = [x_val, y_val],\n",
    "            validation_batch_size = 64,\n",
    "            callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "        )\n",
    "preds_train = np.argmax(trans_learn.predict(x_train_aug), axis = 1)\n",
    "preds_val   = np.argmax(trans_learn.predict(x_val), axis = 1)\n",
    "preds_test  = np.argmax(trans_learn.predict(x_test), axis = 1)\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 14.9663 - accuracy: 0.4975 - val_loss: 0.6944 - val_accuracy: 0.4985\n",
      "Epoch 2/50\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 9.4884 - accuracy: 0.5037 - val_loss: 0.6929 - val_accuracy: 0.5032\n",
      "Epoch 3/50\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 6.5789 - accuracy: 0.5108 - val_loss: 0.6923 - val_accuracy: 0.5076\n",
      "Epoch 4/50\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 4.8447 - accuracy: 0.5147 - val_loss: 0.6922 - val_accuracy: 0.5059\n",
      "Epoch 5/50\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 3.6937 - accuracy: 0.5224 - val_loss: 0.6923 - val_accuracy: 0.4981\n",
      "Epoch 6/50\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 2.8900 - accuracy: 0.5232 - val_loss: 0.6926 - val_accuracy: 0.4988\n",
      "Epoch 7/50\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 2.3407 - accuracy: 0.5219 - val_loss: 0.6927 - val_accuracy: 0.4981\n",
      "1932/1932 [==============================] - 2s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "82/82 [==============================] - 0s 1ms/step\n",
      "Training Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.545     0.725     0.622     30780\n",
      "         1.0      0.594     0.399     0.477     31023\n",
      "\n",
      "    accuracy                          0.561     61803\n",
      "   macro avg      0.569     0.562     0.550     61803\n",
      "weighted avg      0.570     0.561     0.549     61803\n",
      "\n",
      "\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.498     1.000     0.665      1466\n",
      "         1.0      0.000     0.000     0.000      1477\n",
      "\n",
      "    accuracy                          0.498      2943\n",
      "   macro avg      0.249     0.500     0.333      2943\n",
      "weighted avg      0.248     0.498     0.331      2943\n",
      "\n",
      "\n",
      "Testing Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.498     1.000     0.665      1303\n",
      "         1.0      0.000     0.000     0.000      1314\n",
      "\n",
      "    accuracy                          0.498      2617\n",
      "   macro avg      0.249     0.500     0.332      2617\n",
      "weighted avg      0.248     0.498     0.331      2617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), padding = 'same', activation = 'relu', input_shape = x_train_aug[0].shape),\n",
    "    tf.keras.layers.MaxPool2D((3,3), padding = 'same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (2,2), padding = 'same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2), padding = 'same'),\n",
    "\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cnn.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.000005),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = cnn.fit(\n",
    "            x_train_aug, y_train_aug, batch_size = 128,\n",
    "            epochs = 50,\n",
    "            validation_data = [x_val, y_val],\n",
    "            validation_batch_size = 128,\n",
    "            callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "        )\n",
    "preds_train = np.argmax(cnn.predict(x_train_aug), axis = 1)\n",
    "preds_val   = np.argmax(cnn.predict(x_val), axis = 1)\n",
    "preds_test  = np.argmax(cnn.predict(x_test), axis = 1)\n",
    "\n",
    "print(\"Training Classification Report: \\n\", classification_report(y_train_aug, preds_train, digits = N_DIGITS))\n",
    "print(\"\\nValidation Classification Report: \\n\", classification_report(y_val, preds_val, digits = N_DIGITS))\n",
    "print(\"\\nTesting Classification Report: \\n\", classification_report(y_test, preds_test, digits = N_DIGITS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c58e9361bde7ca617934da376e83056db506761bdc9593ca2087fabac973f609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
